{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe3ff947",
   "metadata": {},
   "source": [
    "Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2f66a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kurzer Tracking-Scan f√ºr StatsBomb-Dateien\n",
    "# Keine Zeitlogik, kein Merge, nur grobe Kompatibilit√§tspr√ºfung.\n",
    "# Pfad ggf. anpassen:\n",
    "INPUT_GLOB = \"/Users/tunahansari/football_ra/data/tracking/SB_tracking_*.json.gz\"\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import gzip\n",
    "import json\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Spielfeldma√üe und Schwellenwerte\n",
    "FIELD_LEN = 120.0\n",
    "FIELD_WID = 53.33\n",
    "THRESH_FAIL_XY_NUMERIC = 0.80\n",
    "THRESH_WARN_XY_NUMERIC = 0.99\n",
    "THRESH_WARN_OOB = 0.005\n",
    "THRESH_WARN_PLAYER_ID = 0.95\n",
    "\n",
    "def _to_float(v):\n",
    "    try:\n",
    "        return float(v)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def _first(*vals):\n",
    "    for v in vals:\n",
    "        if v is not None:\n",
    "            return v\n",
    "    return None\n",
    "\n",
    "def _pct(n, d):\n",
    "    return (n / d) if d else 0.0\n",
    "\n",
    "def scan_file(file_path):\n",
    "    # Pr√ºft eine Tracking-Datei auf die wichtigsten Felder\n",
    "    name = os.path.basename(file_path)\n",
    "    try:\n",
    "        with gzip.open(file_path, \"rt\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "    except Exception as e:\n",
    "        return {\"file\": name, \"status\": \"FAIL\", \"reason\": f\"json_error:{e}\"}\n",
    "\n",
    "    plays = data.get(\"plays\", [])\n",
    "    if not isinstance(plays, list) or len(plays) == 0:\n",
    "        return {\"file\": name, \"status\": \"FAIL\", \"reason\": \"no_plays\"}\n",
    "\n",
    "    n_plays = len(plays)\n",
    "    n_tracks = 0\n",
    "    steps_total = 0\n",
    "    xy_numeric = 0\n",
    "    oob = 0\n",
    "    tracks_total = 0\n",
    "    tracks_with_player_id = 0\n",
    "    plays_with_ltr = 0\n",
    "    plays_with_yard = 0\n",
    "\n",
    "    # Beispiel-Keys f√ºr √úbersicht\n",
    "    example_play_keys = set()\n",
    "    example_track_keys = set()\n",
    "    example_step_keys = set()\n",
    "    for p in plays[:10]:\n",
    "        example_play_keys |= set(p.keys())\n",
    "\n",
    "    for play in plays:\n",
    "        if play.get(\"offense_left_to_right\") is not None:\n",
    "            plays_with_ltr += 1\n",
    "        if _to_float(play.get(\"play_yardline\")) is not None:\n",
    "            plays_with_yard += 1\n",
    "\n",
    "        tracks = play.get(\"tracks\", [])\n",
    "        if isinstance(tracks, list):\n",
    "            n_tracks += len(tracks)\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        for tr in tracks:\n",
    "            tracks_total += 1\n",
    "            example_track_keys |= set(tr.keys())\n",
    "\n",
    "            player = tr.get(\"player\") or tr.get(\"track_player\") or {}\n",
    "            if isinstance(player, dict) and player.get(\"player_id\") is not None:\n",
    "                tracks_with_player_id += 1\n",
    "\n",
    "            steps = tr.get(\"steps\") or tr.get(\"track_steps\") or []\n",
    "            for s in steps[:10]:\n",
    "                if isinstance(s, dict):\n",
    "                    example_step_keys |= set(s.keys())\n",
    "\n",
    "            for s in steps:\n",
    "                steps_total += 1\n",
    "                x = _to_float(_first(s.get(\"x\"), s.get(\"ngs_x\")))\n",
    "                y = _to_float(_first(s.get(\"y\"), s.get(\"ngs_y\")))\n",
    "                if x is not None and y is not None:\n",
    "                    xy_numeric += 1\n",
    "                    if not (0.0 <= x <= FIELD_LEN) or not (0.0 <= y <= FIELD_WID):\n",
    "                        oob += 1\n",
    "\n",
    "    r_xy_numeric = _pct(xy_numeric, steps_total)\n",
    "    r_oob = _pct(oob, max(xy_numeric, 1))\n",
    "    r_player_id = _pct(tracks_with_player_id, max(tracks_total, 1))\n",
    "    r_play_ltr = _pct(plays_with_ltr, max(n_plays, 1))\n",
    "    r_yardline = _pct(plays_with_yard, max(n_plays, 1))\n",
    "\n",
    "    # Status-Logik\n",
    "    status = \"PASS\"\n",
    "    reasons = []\n",
    "    if steps_total == 0:\n",
    "        status = \"FAIL\"\n",
    "        reasons.append(\"no_steps\")\n",
    "    if r_xy_numeric < THRESH_FAIL_XY_NUMERIC:\n",
    "        status = \"FAIL\"\n",
    "        reasons.append(f\"xy_numeric<{int(THRESH_FAIL_XY_NUMERIC*100)}%\")\n",
    "    elif r_xy_numeric < THRESH_WARN_XY_NUMERIC:\n",
    "        if status != \"FAIL\":\n",
    "            status = \"WARN\"\n",
    "            reasons.append(f\"xy_numeric<{int(THRESH_WARN_XY_NUMERIC*100)}%\")\n",
    "    if r_oob > THRESH_WARN_OOB:\n",
    "        if status != \"FAIL\":\n",
    "            status = \"WARN\"\n",
    "            reasons.append(f\"oob>{THRESH_WARN_OOB*100:.1f}%\")\n",
    "    if r_player_id < THRESH_WARN_PLAYER_ID:\n",
    "        if status != \"FAIL\":\n",
    "            status = \"WARN\"\n",
    "            reasons.append(f\"player_id<{int(THRESH_WARN_PLAYER_ID*100)}%\")\n",
    "\n",
    "    return {\n",
    "        \"file\": name,\n",
    "        \"status\": status,\n",
    "        \"reason\": \";\".join(reasons),\n",
    "        \"n_plays\": n_plays,\n",
    "        \"n_tracks\": n_tracks,\n",
    "        \"steps_total\": steps_total,\n",
    "        \"r_xy_numeric\": r_xy_numeric,\n",
    "        \"r_oob\": r_oob,\n",
    "        \"r_player_id\": r_player_id,\n",
    "        \"r_play_ltr\": r_play_ltr,\n",
    "        \"r_yardline\": r_yardline,\n",
    "        \"example_play_keys\": \", \".join(sorted(list(example_play_keys))[:30]),\n",
    "        \"example_track_keys\": \", \".join(sorted(list(example_track_keys))[:30]),\n",
    "        \"example_step_keys\": \", \".join(sorted(list(example_step_keys))[:30]),\n",
    "    }\n",
    "\n",
    "# Scan ausf√ºhren\n",
    "files = sorted(glob.glob(INPUT_GLOB))\n",
    "if not files:\n",
    "    raise FileNotFoundError(f\"Keine Dateien f√ºr Muster: {INPUT_GLOB}\")\n",
    "\n",
    "print(f\"Tracking-Scan: {len(files)} Dateien gefunden\")\n",
    "results = []\n",
    "for i, fp in enumerate(files, 1):\n",
    "    name = os.path.basename(fp)\n",
    "    print(f\"[{i}/{len(files)}] {name} ... \", end=\"\")\n",
    "    res = scan_file(fp)\n",
    "    print(f\"{res['status']} {('('+res['reason']+')') if res['reason'] else ''}\")\n",
    "    results.append(res)\n",
    "\n",
    "df_scan = pd.DataFrame(results)\n",
    "print(\"\\nStatus-√úbersicht:\")\n",
    "print(df_scan[\"status\"].value_counts())\n",
    "\n",
    "# DataFrame anzeigen\n",
    "try:\n",
    "    from IPython.display import display\n",
    "    display(df_scan.sort_values([\"status\", \"file\"]))\n",
    "except:\n",
    "    print(df_scan.head(20).to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73876163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# H√§ufigkeit der Gr√ºnde f√ºr WARN/FAIL\n",
    "from collections import Counter\n",
    "\n",
    "reason_counts = Counter()\n",
    "for r in df_scan['reason'].fillna(''):\n",
    "    for part in [p for p in r.split(';') if p]:\n",
    "        reason_counts[part] += 1\n",
    "print(\"WARN/FAIL-Gr√ºnde (H√§ufigkeit):\")\n",
    "for k,v in reason_counts.most_common():\n",
    "    print(f\"  {k}: {v}\")\n",
    "\n",
    "# Top-10 mit h√∂chstem OOB-Anteil\n",
    "cols = [\"file\",\"status\",\"r_oob\",\"r_xy_numeric\",\"r_player_id\"]\n",
    "print(\"\\nTop-10 OOB:\")\n",
    "display(df_scan.sort_values(\"r_oob\", ascending=False)[cols].head(10))\n",
    "\n",
    "# Dateien mit xy_numeric<99% \n",
    "print(\"\\nxy_numeric<99%:\")\n",
    "display(df_scan[df_scan[\"r_xy_numeric\"] < 0.99][cols].sort_values(\"r_xy_numeric\").head(20))\n",
    "\n",
    "# Pr√§senzraten der Play-Felder\n",
    "print(\"\\nDurchschnittliche Pr√§senz (√ºber Dateien):\")\n",
    "print(\"offense_left_to_right  (mean r_play_ltr):\", df_scan[\"r_play_ltr\"].mean().round(3))\n",
    "print(\"play_yardline          (mean r_yardline):\", df_scan[\"r_yardline\"].mean().round(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8559b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse der Tracking-Daten\n",
    "\n",
    "INPUT_GLOB = \"/Users/tunahansari/football_ra/data/tracking/SB_tracking_*.json.gz\"\n",
    "\n",
    "import os, glob, gzip, json, math\n",
    "from collections import defaultdict, Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "FIELD_LEN = 120.0\n",
    "FIELD_WID  = 53.33\n",
    "\n",
    "def _to_float(v):\n",
    "    try:\n",
    "        return float(v)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def _first(*vals):\n",
    "    for v in vals:\n",
    "        if v is not None:\n",
    "            return v\n",
    "    return None\n",
    "#\n",
    "def _oob_overshoot_mag(x, y):\n",
    "    \"\"\"Au√üerhalb des Rechtecks.\n",
    "       0 wenn in bounds, sonst Distanz zum n√§chstliegenden Rand.\"\"\"\n",
    "    ox = 0.0\n",
    "    oy = 0.0\n",
    "    if x is not None and y is not None:\n",
    "        if x < 0: ox = 0 - x\n",
    "        elif x > FIELD_LEN: ox = x - FIELD_LEN\n",
    "        if y < 0: oy = 0 - y\n",
    "        elif y > FIELD_WID: oy = y - FIELD_WID\n",
    "    return math.hypot(ox, oy)\n",
    "\n",
    "def _bin_overshoot(m):\n",
    "    \"\"\"Bins f√ºr OOB-Schweregrad in yards.\"\"\"\n",
    "    if m <= 0:          return \"in_bounds\"\n",
    "    elif m <= 0.5:      return \"<=0.5y\"\n",
    "    elif m <= 1.0:      return \"0.5‚Äì1y\"\n",
    "    elif m <= 2.0:      return \"1‚Äì2y\"\n",
    "    else:               return \">2y\"\n",
    "\n",
    "# Hauptanalyse\n",
    "files = sorted(glob.glob(INPUT_GLOB))\n",
    "if not files:\n",
    "    raise FileNotFoundError(f\"Keine Dateien f√ºr Muster: {INPUT_GLOB}\")\n",
    "\n",
    "print(f\"üîé Zusatz-QA: {len(files)} Dateien\")\n",
    "\n",
    "# Aggregatoren pro Datei\n",
    "per_file = []\n",
    "\n",
    "# Play-Qualit√§t (xy-Anteil) pro Play\n",
    "play_quality = {}  # key=(file, play_uuid) -> dict: steps_total, xy_numeric\n",
    "play_lengths = []  # Liste aller Play-Dauern\n",
    "\n",
    "# Positions-Stats\n",
    "position_counts_global = Counter()\n",
    "tracks_with_pos = 0\n",
    "tracks_total     = 0\n",
    "\n",
    "for i, fp in enumerate(files, 1):\n",
    "    name = os.path.basename(fp)\n",
    "    print(f\"[{i:03d}/{len(files)}] Analysiere {name} ...\", flush=True)\n",
    "\n",
    "    # Z√§hler f√ºr Datei\n",
    "    steps_total = 0\n",
    "    steps_xy_ok = 0\n",
    "    oob_bins = Counter()   # in_bounds, (<=0.5y, 0.5‚Äì1y, 1‚Äì2y, >2y)\n",
    "    plays_in_file = 0\n",
    "    plays_with_tss = 0\n",
    "    positions_in_file = Counter()\n",
    "    tracks_with_pos_file = 0\n",
    "    tracks_total_file = 0\n",
    "\n",
    "    #  # F√ºr Play-L√§ngen, pro Play max(tss >= 0)\n",
    "    play_max_tss = {}  \n",
    "\n",
    "    # F√ºr xy-Qualit√§t pro Play\n",
    "    play_xy_steps = defaultdict(lambda: {\"steps_total\":0, \"xy_numeric\":0})\n",
    "\n",
    "    with gzip.open(fp, \"rt\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    plays = data.get(\"plays\", [])\n",
    "    plays_in_file = len(plays)\n",
    "\n",
    "    for play in plays:\n",
    "        play_uuid = play.get(\"play_uuid\")\n",
    "\n",
    "        tracks = play.get(\"tracks\", []) or []\n",
    "        for tr in tracks:\n",
    "            tracks_total += 1\n",
    "            tracks_total_file += 1\n",
    "\n",
    "            # Positionsfeld (nur Statistik)\n",
    "            player = tr.get(\"player\", tr.get(\"track_player\", {})) or {}\n",
    "            pos = player.get(\"position_code\")\n",
    "            if pos:\n",
    "                positions_in_file[pos] += 1\n",
    "                position_counts_global[pos] += 1\n",
    "                tracks_with_pos      += 1\n",
    "                tracks_with_pos_file += 1\n",
    "\n",
    "            steps = tr.get(\"steps\", tr.get(\"track_steps\", [])) or []\n",
    "            for s in steps:\n",
    "                steps_total += 1\n",
    "                play_xy_steps[(name, play_uuid)][\"steps_total\"] += 1\n",
    "\n",
    "                x = _to_float(_first(s.get(\"x\"), s.get(\"ngs_x\")))\n",
    "                y = _to_float(_first(s.get(\"y\"), s.get(\"ngs_y\")))\n",
    "                if x is not None and y is not None:\n",
    "                    steps_xy_ok += 1\n",
    "                    play_xy_steps[(name, play_uuid)][\"xy_numeric\"] += 1\n",
    "                    # OOB-Schweregrad\n",
    "                    m = _oob_overshoot_mag(x, y)\n",
    "                    oob_bins[_bin_overshoot(m)] += 1\n",
    "                else:\n",
    "                    # kein xy -> z√§hlt nur zu steps_total/play_xy_steps.steps_total\n",
    "                    pass\n",
    "\n",
    "                # Play-L√§nge (nur 'Analyse', keine Normierung)\n",
    "                tss = _to_float(s.get(\"time_since_snap\"))\n",
    "                if tss is not None and tss >= 0:\n",
    "                    prev = play_max_tss.get(play_uuid)\n",
    "                    play_max_tss[play_uuid] = tss if (prev is None or tss > prev) else prev\n",
    "\n",
    "    # Datei-Ergebnis\n",
    "    valid_xy = steps_xy_ok\n",
    "    in_bounds = oob_bins.get(\"in_bounds\", 0)\n",
    "    oob_count = (valid_xy - in_bounds)\n",
    "\n",
    "    # Anteile bezogen auf g√ºltige xy\n",
    "    def _share(key):\n",
    "        denom = max(valid_xy, 1)\n",
    "        return oob_bins.get(key, 0) / denom\n",
    "\n",
    "    per_file.append({\n",
    "        \"file\": name,\n",
    "        \"steps_total\": steps_total,\n",
    "        \"xy_valid\": valid_xy,\n",
    "        \"xy_valid_share\": (valid_xy / max(steps_total,1)),\n",
    "        \"oob_share_total\": (oob_count / max(valid_xy,1)),\n",
    "        \"oob_<=0.5y\": _share(\"<=0.5y\"),\n",
    "        \"oob_0.5‚Äì1y\": _share(\"0.5‚Äì1y\"),\n",
    "        \"oob_1‚Äì2y\": _share(\"1‚Äì2y\"),\n",
    "        \"oob_>2y\": _share(\">2y\"),\n",
    "        \"tracks_with_pos_share\": tracks_with_pos_file / max(tracks_total_file,1),\n",
    "        \"plays_in_file\": plays_in_file,\n",
    "    })\n",
    "\n",
    "    # Play-L√§ngen sammeln\n",
    "    for puid, tmax in play_max_tss.items():\n",
    "        play_lengths.append(tmax)\n",
    "\n",
    "    # Play-Qualit√§t (xy-Anteil) sammeln\n",
    "    for key, d in play_xy_steps.items():\n",
    "        play_quality[key] = {\n",
    "            \"file\": key[0],\n",
    "            \"play_uuid\": key[1],\n",
    "            \"steps_total\": d[\"steps_total\"],\n",
    "            \"xy_valid\": d[\"xy_numeric\"],\n",
    "            \"xy_valid_share\": d[\"xy_numeric\"] / max(d[\"steps_total\"],1)\n",
    "        }\n",
    "\n",
    "# Ergebnisse in DataFrames\n",
    "df_files = pd.DataFrame(per_file).sort_values(\"oob_share_total\", ascending=False)\n",
    "df_plays = pd.DataFrame(play_quality.values()).sort_values(\"xy_valid_share\")\n",
    "\n",
    "print(\"\\n Zusatz-QA fertig.\\n\")\n",
    "\n",
    "# 1) OOB-Schweregrad\n",
    "print(\"1) OOB-Schweregrad (global, Anteil an g√ºltigen Punkten) ‚Äì gemittelt √ºber Dateien:\")\n",
    "cols_oob = [\"oob_share_total\",\"oob_<=0.5y\",\"oob_0.5‚Äì1y\",\"oob_1‚Äì2y\",\"oob_>2y\"]\n",
    "print(df_files[cols_oob].mean().round(4).to_string())\n",
    "\n",
    "print(\"\\nTop-10 Dateien nach OOB-Gesamtanteil:\")\n",
    "display(df_files[[\"file\",\"oob_share_total\",\"oob_<=0.5y\",\"oob_0.5‚Äì1y\",\"oob_1‚Äì2y\",\"oob_>2y\",\"xy_valid_share\"]].head(10))\n",
    "\n",
    "# 2) xy-L√ºcken ‚Äì schlechteste Plays\n",
    "print(\"\\n2) Schlechteste 15 Plays nach xy_valid_share:\")\n",
    "display(df_plays[[\"file\",\"play_uuid\",\"steps_total\",\"xy_valid\",\"xy_valid_share\"]].head(15))\n",
    "\n",
    "# 3) Positionsabdeckung\n",
    "print(\"\\n3) Positionsabdeckung:\")\n",
    "pos_total = sum(position_counts_global.values())\n",
    "pos_df = (pd.Series(position_counts_global, name=\"count\")\n",
    "            .sort_values(ascending=False)\n",
    "            .to_frame())\n",
    "pos_df[\"share\"] = pos_df[\"count\"] / max(pos_total,1)\n",
    "display(pos_df)\n",
    "\n",
    "print(\"\\nAnteil Tracks mit position_code ‚Äì pro Datei (Top 10 niedrigste):\")\n",
    "display(df_files[[\"file\",\"tracks_with_pos_share\"]].sort_values(\"tracks_with_pos_share\").head(10))\n",
    "\n",
    "# 4) Play-L√§ngen (Sekunden ab Snap)\n",
    "if play_lengths:\n",
    "    arr = np.array(play_lengths)\n",
    "    summary = {\n",
    "        \"count\": int(arr.size),\n",
    "        \"min\": round(float(arr.min()), 3),\n",
    "        \"p25\": round(float(np.percentile(arr, 25)), 3),\n",
    "        \"median\": round(float(np.percentile(arr, 50)), 3),\n",
    "        \"p75\": round(float(np.percentile(arr, 75)), 3),\n",
    "        \"p90\": round(float(np.percentile(arr, 90)), 3),\n",
    "        \"p95\": round(float(np.percentile(arr, 95)), 3),\n",
    "        \"max\": round(float(arr.max()), 3),\n",
    "        \">=4s\": int((arr >= 4.0).sum()),\n",
    "        \">=5s\": int((arr >= 5.0).sum()),\n",
    "        \">=6s\": int((arr >= 6.0).sum()),\n",
    "    }\n",
    "    print(\"\\n4) Play-L√§ngen (Sekunden, nur wenn time_since_snap vorhanden):\")\n",
    "    for k,v in summary.items():\n",
    "        print(f\"  {k}: {v}\")\n",
    "else:\n",
    "    print(\"\\n4) Play-L√§ngen: Keine time_since_snap gefunden ‚Äì L√§nge nicht auswertbar.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018a0b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting der OOB-Anteile pro Play\n",
    "\n",
    "INPUT_GLOB = \"/Users/tunahansari/football_ra/data/tracking/SB_tracking_*.json.gz\"\n",
    "TOP_FILES = 3              # wie viele Dateien mit h√∂chstem OOB-Anteil anschauen\n",
    "TOP_PLAYS_PER_FILE = 2     # wie viele Plays je Datei (h√∂chster OOB-Anteil) plotten\n",
    "MAX_STEPS_PLOT = None     \n",
    "\n",
    "import os, glob, gzip, json, math\n",
    "from collections import defaultdict, Counter\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "FIELD_LEN, FIELD_WID = 120.0, 53.33\n",
    "\n",
    "def _to_float(v):\n",
    "    try:\n",
    "        return float(v)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def _first(*vals):\n",
    "    for v in vals:\n",
    "        if v is not None:\n",
    "            return v\n",
    "    return None\n",
    "\n",
    "def file_oob_ratio(file_path):\n",
    "    \"\"\"Grober OOB-Anteil pro Datei (nur g√ºltige xy z√§hlen als Basis).\"\"\"\n",
    "    steps_valid = 0\n",
    "    oob = 0\n",
    "    with gzip.open(file_path, \"rt\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    for play in data.get(\"plays\", []):\n",
    "        for tr in play.get(\"tracks\", []) or []:\n",
    "            for s in tr.get(\"steps\", tr.get(\"track_steps\", [])) or []:\n",
    "                x = _to_float(_first(s.get(\"x\"), s.get(\"ngs_x\")))\n",
    "                y = _to_float(_first(s.get(\"y\"), s.get(\"ngs_y\")))\n",
    "                if x is None or y is None:\n",
    "                    continue\n",
    "                steps_valid += 1\n",
    "                if not (0.0 <= x <= FIELD_LEN) or not (0.0 <= y <= FIELD_WID):\n",
    "                    oob += 1\n",
    "    return (oob / steps_valid) if steps_valid else 0.0\n",
    "\n",
    "def plays_oob_stats(file_path):\n",
    "    \"\"\"Per-Play OOB-Anteil + Rohpunkte (lazy) f√ºr sp√§tere Auswahl/Plot.\"\"\"\n",
    "    with gzip.open(file_path, \"rt\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    by_play = defaultdict(lambda: {\"valid\":0, \"oob\":0})\n",
    "    # F√ºr Plot speichern wir pro Play nur die Punkte (x,y) als zwei Listen (in/out)\n",
    "    raw_points = defaultdict(lambda: {\"in\": [], \"out\": []})\n",
    "\n",
    "    for play in data.get(\"plays\", []):\n",
    "        puid = play.get(\"play_uuid\")\n",
    "        for tr in play.get(\"tracks\", []) or []:\n",
    "            steps = tr.get(\"steps\", tr.get(\"track_steps\", [])) or []\n",
    "            for idx, s in enumerate(steps):\n",
    "                x = _to_float(_first(s.get(\"x\"), s.get(\"ngs_x\")))\n",
    "                y = _to_float(_first(s.get(\"y\"), s.get(\"ngs_y\")))\n",
    "                if x is None or y is None:\n",
    "                    continue\n",
    "                by_play[puid][\"valid\"] += 1\n",
    "                in_bounds = (0.0 <= x <= FIELD_LEN) and (0.0 <= y <= FIELD_WID)\n",
    "                if in_bounds:\n",
    "                    raw_points[puid][\"in\"].append((x,y))\n",
    "                else:\n",
    "                    by_play[puid][\"oob\"] += 1\n",
    "                    raw_points[puid][\"out\"].append((x,y))\n",
    "\n",
    "    rows = []\n",
    "    for puid, d in by_play.items():\n",
    "        valid = d[\"valid\"]\n",
    "        oob = d[\"oob\"]\n",
    "        share = (oob / valid) if valid else 0.0\n",
    "        rows.append((puid, valid, oob, share))\n",
    "    rows.sort(key=lambda t: t[3], reverse=True)  # nach OOB-Anteil\n",
    "    return rows, raw_points\n",
    "\n",
    "def plot_play_scatter(file_name, play_uuid, raw_points):\n",
    "    \"\"\"Ein Plot pro Play: In-bounds Punkte '.' und OOB Punkte 'x'. Keine Farben gesetzt.\"\"\"\n",
    "    pts_in  = raw_points[play_uuid][\"in\"]\n",
    "    pts_out = raw_points[play_uuid][\"out\"]\n",
    "\n",
    "    # Steps begrenzen (nur f√ºr sehr gro√üe Plays)\n",
    "    if MAX_STEPS_PLOT is not None:\n",
    "        pts_in  = pts_in[:MAX_STEPS_PLOT]\n",
    "        pts_out = pts_out[:MAX_STEPS_PLOT]\n",
    "\n",
    "    plt.figure(figsize=(7.0, 3.6))\n",
    "\n",
    "    # In-bounds als Punkte\n",
    "    if pts_in:\n",
    "        xi, yi = zip(*pts_in)\n",
    "        plt.plot(xi, yi, '.', markersize=2, label=\"in-bounds\")\n",
    "\n",
    "    # OOB als X-Marker\n",
    "    if pts_out:\n",
    "        xo, yo = zip(*pts_out)\n",
    "        plt.plot(xo, yo, 'x', markersize=3, label=\"OOB\")\n",
    "\n",
    "    # Feldrahmen\n",
    "    plt.axvline(0); plt.axvline(FIELD_LEN)\n",
    "    plt.axhline(0); plt.axhline(FIELD_WID)\n",
    "    plt.xlim(-2, FIELD_LEN+2)\n",
    "    plt.ylim(-2, FIELD_WID+2)\n",
    "    plt.xlabel(\"x (yards)\")\n",
    "    plt.ylabel(\"y (yards)\")\n",
    "    plt.title(f\"{file_name} | play={play_uuid}\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Dateien nach OOB-Anteil sortieren und Top ausw√§hlen\n",
    "files = sorted(glob.glob(INPUT_GLOB))\n",
    "if not files:\n",
    "    raise FileNotFoundError(f\"Keine Dateien f√ºr Muster: {INPUT_GLOB}\")\n",
    "print(f\" W√§hle Top-{TOP_FILES} Dateien mit h√∂chstem OOB-Anteil ‚Ä¶\")\n",
    "file_scores = []\n",
    "for i, fp in enumerate(files, 1):\n",
    "    name = os.path.basename(fp)\n",
    "    print(f\"  [{i:03d}/{len(files)}] Scanne {name} ‚Ä¶\", end=\"\", flush=True)\n",
    "    score = file_oob_ratio(fp)\n",
    "    file_scores.append((name, fp, score))\n",
    "    print(f\" OOB={score:.4%}\")\n",
    "file_scores.sort(key=lambda t: t[2], reverse=True)\n",
    "top_files = file_scores[:TOP_FILES]\n",
    "print(\"\\n Top-Dateien:\")\n",
    "for name, _, sc in top_files:\n",
    "    print(f\"   {name}: OOB‚âà{sc:.2%}\")\n",
    "\n",
    "# Aus jeder Top-Datei die schlimmsten Plays w√§hlen & plotten\n",
    "for name, fp, sc in top_files:\n",
    "    print(f\"\\n Datei: {name} (OOB‚âà{sc:.2%}) ‚Üí ermittle Top-{TOP_PLAYS_PER_FILE} Plays ‚Ä¶\")\n",
    "    rows, raw_points = plays_oob_stats(fp)\n",
    "    picks = rows[:TOP_PLAYS_PER_FILE]\n",
    "    for (puid, valid, oob, share) in picks:\n",
    "        print(f\"  ‚Ä¢ Play {puid}: valid={valid}, oob={oob}, OOB-Anteil={share:.2%} ‚Üí plot\")\n",
    "        plot_play_scatter(name, puid, raw_points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e8b6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zusatz-Analyse: OOB-Anteile pro Play\n",
    "\n",
    "INPUT_GLOB = \"/Users/tunahansari/football_ra/data/tracking/SB_tracking_*.json.gz\"\n",
    "TOP_FILES = 3            # wie viele Dateien mit h√∂chstem OOB-Anteil pr√ºfen\n",
    "TOP_PLAYS_PER_FILE = 2   # pro Datei wie viele Plays (mit h√∂chstem OOB-Anteil)\n",
    "\n",
    "import os, glob, gzip, json, math\n",
    "from collections import defaultdict, Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "FIELD_LEN, FIELD_WID = 120.0, 53.33\n",
    "\n",
    "def _to_float(v):\n",
    "    try: return float(v)\n",
    "    except Exception: return None\n",
    "\n",
    "def _first(*vals):\n",
    "    for v in vals:\n",
    "        if v is not None:\n",
    "            return v\n",
    "    return None\n",
    "\n",
    "def _oob(x, y):\n",
    "    return not (0.0 <= x <= FIELD_LEN) or not (0.0 <= y <= FIELD_WID)\n",
    "\n",
    "def _overshoot_mag(x, y):\n",
    "    ox = (0 - x) if x < 0 else (x - FIELD_LEN) if x > FIELD_LEN else 0.0\n",
    "    oy = (0 - y) if y < 0 else (y - FIELD_WID) if y > FIELD_WID else 0.0\n",
    "    return math.hypot(ox, oy)\n",
    "\n",
    "def _bin_overshoot(m):\n",
    "    if m <= 0:   return \"in_bounds\"\n",
    "    if m <= 0.5: return \"<=0.5y\"\n",
    "    if m <= 1.0: return \"0.5‚Äì1y\"\n",
    "    if m <= 2.0: return \"1‚Äì2y\"\n",
    "    return \">2y\"\n",
    "\n",
    "def file_oob_ratio(fp):\n",
    "    steps_valid = 0; oob = 0\n",
    "    with gzip.open(fp, \"rt\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    for play in data.get(\"plays\", []):\n",
    "        for tr in play.get(\"tracks\", []) or []:\n",
    "            for s in tr.get(\"steps\", tr.get(\"track_steps\", [])) or []:\n",
    "                x = _to_float(_first(s.get(\"x\"), s.get(\"ngs_x\"))); y = _to_float(_first(s.get(\"y\"), s.get(\"ngs_y\")))\n",
    "                if x is None or y is None: continue\n",
    "                steps_valid += 1\n",
    "                if _oob(x,y): oob += 1\n",
    "    return (oob/steps_valid) if steps_valid else 0.0\n",
    "\n",
    "def plays_oob_with_cal(fp):\n",
    "    \"\"\"Gibt pro Play: valid, oob, oob_cal_true, oob_cal_false, OOB-Bins zur√ºck (Liste von Dicts, sortiert).\"\"\"\n",
    "    with gzip.open(fp, \"rt\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    per = {}\n",
    "    bins = {}\n",
    "    for play in data.get(\"plays\", []):\n",
    "        puid = play.get(\"play_uuid\")\n",
    "        if puid not in per:\n",
    "            per[puid] = {\"play_uuid\": puid, \"valid\":0, \"oob\":0, \"oob_cal_true\":0, \"oob_cal_false\":0}\n",
    "            bins[puid] = Counter()\n",
    "        for tr in play.get(\"tracks\", []) or []:\n",
    "            for s in tr.get(\"steps\", tr.get(\"track_steps\", [])) or []:\n",
    "                x = _to_float(_first(s.get(\"x\"), s.get(\"ngs_x\"))); y = _to_float(_first(s.get(\"y\"), s.get(\"ngs_y\")))\n",
    "                if x is None or y is None: continue\n",
    "                per[puid][\"valid\"] += 1\n",
    "                if _oob(x,y):\n",
    "                    per[puid][\"oob\"] += 1\n",
    "                    cal = s.get(\"calibration_fault\")\n",
    "                    if cal is None: cal = s.get(\"step_calibration_fault\")\n",
    "                    if bool(cal): per[puid][\"oob_cal_true\"] += 1\n",
    "                    else:         per[puid][\"oob_cal_false\"] += 1\n",
    "                    bins[puid][_bin_overshoot(_overshoot_mag(x,y))] += 1\n",
    "    rows = []\n",
    "    for puid, d in per.items():\n",
    "        valid = d[\"valid\"]; oob = d[\"oob\"]\n",
    "        share = (oob/valid) if valid else 0.0\n",
    "        row = {\n",
    "            \"play_uuid\": puid,\n",
    "            \"valid\": valid,\n",
    "            \"oob\": oob,\n",
    "            \"oob_share\": share,\n",
    "            \"oob_cal_true\": d[\"oob_cal_true\"],\n",
    "            \"oob_cal_true_share\": (d[\"oob_cal_true\"]/oob) if oob else 0.0,\n",
    "            \"oob_cal_false\": d[\"oob_cal_false\"],\n",
    "            \"oob_cal_false_share\": (d[\"oob_cal_false\"]/oob) if oob else 0.0,\n",
    "            \"oob_<=0.5y\": bins[puid][\"<=0.5y\"] / max(oob,1),\n",
    "            \"oob_0.5‚Äì1y\": bins[puid][\"0.5‚Äì1y\"] / max(oob,1),\n",
    "            \"oob_1‚Äì2y\":   bins[puid][\"1‚Äì2y\"]   / max(oob,1),\n",
    "            \"oob_>2y\":    bins[puid][\">2y\"]    / max(oob,1),\n",
    "        }\n",
    "        rows.append(row)\n",
    "    rows.sort(key=lambda r: r[\"oob_share\"], reverse=True)\n",
    "    return rows\n",
    "\n",
    "# Auswahl Top-Dateien nach OOB- Anteil\n",
    "files = sorted(glob.glob(INPUT_GLOB))\n",
    "if not files: raise FileNotFoundError(\"Keine Dateien gefunden.\")\n",
    "scores = [(os.path.basename(fp), fp, file_oob_ratio(fp)) for fp in files]\n",
    "scores.sort(key=lambda t: t[2], reverse=True)\n",
    "top = scores[:TOP_FILES]\n",
    "print(\"Top-Dateien (h√∂chster OOB-Anteil):\")\n",
    "for name, _, sc in top:\n",
    "    print(f\"  {name}: OOB‚âà{sc:.2%}\")\n",
    "\n",
    "# Pr√ºfe Plays in den Top-Dateien\n",
    "all_rows = []\n",
    "for name, fp, sc in top:\n",
    "    print(f\"\\n {name} ‚Äî pr√ºfe Plays ‚Ä¶\")\n",
    "    rows = plays_oob_with_cal(fp)[:TOP_PLAYS_PER_FILE]\n",
    "    for r in rows:\n",
    "        r[\"file\"] = name\n",
    "        all_rows.append(r)\n",
    "        print(f\"  ‚Ä¢ play={r['play_uuid']} | OOB={r['oob']}/{r['valid']} ({r['oob_share']:.2%}), \"\n",
    "              f\"cal_true={r['oob_cal_true']}/{r['oob']} ({r['oob_cal_true_share']:.2%})\")\n",
    "\n",
    "df_check = pd.DataFrame(all_rows, columns=[\n",
    "    \"file\",\"play_uuid\",\"valid\",\"oob\",\"oob_share\",\n",
    "    \"oob_cal_true\",\"oob_cal_true_share\",\"oob_cal_false\",\"oob_cal_false_share\",\n",
    "    \"oob_<=0.5y\",\"oob_0.5‚Äì1y\",\"oob_1‚Äì2y\",\"oob_>2y\"\n",
    "]).sort_values([\"file\",\"oob_share\"], ascending=[True, False])\n",
    "\n",
    "display(df_check)\n",
    "\n",
    "# Aggregierte Aussage √ºber die Stichprobe:\n",
    "if not df_check.empty:\n",
    "    agg = {\n",
    "        \"plays_geprueft\": len(df_check),\n",
    "        \"median_oob_share\": df_check[\"oob_share\"].median(),\n",
    "        \"median_cal_true_share\": df_check[\"oob_cal_true_share\"].median(),\n",
    "        \"mean_cal_true_share\": df_check[\"oob_cal_true_share\"].mean(),\n",
    "        \"mean_oob_gt2y_share\": df_check[\"oob_>2y\"].mean(),\n",
    "    }\n",
    "    print(\"\\nZusammenfassung (Stichprobe):\")\n",
    "    for k,v in agg.items():\n",
    "        print(f\"  {k}: {v:.3f}\" if isinstance(v, float) else f\"  {k}: {v}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6aebad",
   "metadata": {},
   "source": [
    "Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff669cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tracking-Daten scannen\n",
    "\n",
    "import os, glob, gzip, json, math\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "INPUT_GLOB = \"/Users/tunahansari/football_ra/data/tracking/SB_tracking_*.json.gz\"\n",
    "\n",
    "# Output pro Datei speichern\n",
    "OUTPUT_DIR = Path(\"/Users/tunahansari/football_ra/out_simple\")\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Master-Output (Zusammenf√ºhrung)\n",
    "MASTER_OUT_DIR = Path(\"/Users/tunahansari/football_ra/out_1hz_clean\")\n",
    "MASTER_OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "MASTER_BASENAME = \"master_1hz_4s_ready\"  \n",
    "\n",
    "# Bestehende Outputs √ºberschreiben?\n",
    "FORCE_OVERWRITE = False\n",
    "\n",
    "# Master bauen?\n",
    "REBUILD_MASTER = False  # Auf True setzen, um Master zu erstellen\n",
    "\n",
    "# Einheit: \"yards\", \"feet\" oder None (automatisch ermitteln)\n",
    "FORCE_UNITS = None\n",
    "\n",
    "WINDOW_SECONDS = 4             # Zeitfenster in Sekunden\n",
    "PLAY_MIN_VALID_SHARE = 0.90    # Mindestanteil g√ºltiger Schritte pro Play\n",
    "OOB_DROP_YARDS = 2.0           # OOB-Schwellenwert in Yards\n",
    "FIELD_LEN, FIELD_WID = 120.0, 53.33\n",
    "ENDZONE = 10.0\n",
    "\n",
    "print(f\"Config: files='{INPUT_GLOB}', out='{OUTPUT_DIR}', master='{MASTER_OUT_DIR}', overwrite={FORCE_OVERWRITE}, rebuild_master={REBUILD_MASTER}\")\n",
    "\n",
    "# ----- Hilfsfunktionen -----\n",
    "def _to_float(v):\n",
    "    try:\n",
    "        x = float(v)\n",
    "        if math.isnan(x):\n",
    "            return None\n",
    "        return x\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def _overshoot_mag(x, y):\n",
    "    # Abstand au√üerhalb des Spielfelds berechnen\n",
    "    ox = (0 - x) if x < 0 else (x - FIELD_LEN) if x > FIELD_LEN else 0.0\n",
    "    oy = (0 - y) if y < 0 else (y - FIELD_WID) if y > FIELD_WID else 0.0\n",
    "    return math.hypot(ox, oy)\n",
    "\n",
    "def _clip_xy(x, y):\n",
    "    # (x,y) an Spielfeldgrenzen anpassen\n",
    "    return (min(max(x, 0.0), FIELD_LEN), min(max(y, 0.0), FIELD_WID))\n",
    "\n",
    "def _safe_parquet_path(base_dir: Path, stem: str, ts: bool = True) -> Path:\n",
    "    \"\"\"Erzeuge sicheren Speicherpfad mit Zeitstempel.\"\"\"\n",
    "    if ts:\n",
    "        tag = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "        return base_dir / f\"{stem}_{tag}.parquet\"\n",
    "    return base_dir / f\"{stem}.parquet\"\n",
    "\n",
    "def _save_parquet(df: pd.DataFrame, out_path: Path):\n",
    "    try:\n",
    "        df.to_parquet(out_path, index=False, engine=\"pyarrow\")\n",
    "        print(f\" gespeichert: {out_path} (Zeilen: {len(df):,})\")\n",
    "    except Exception as e:\n",
    "        fb = out_path.with_suffix(\".pkl\")\n",
    "        df.to_pickle(fb)\n",
    "        print(f\" Parquet fehlgeschlagen ({e}); Fallback: {fb}\")\n",
    "\n",
    "def _pick_xy_keys(first_play):\n",
    "    # Ermitteln plausible (x,y)-Schl√ºssel aus ersten Daten\n",
    "    XY_KEYS = [(\"x\",\"y\"), (\"track_x\",\"track_y\"), (\"ngs_x\",\"ngs_y\"), (\"px\",\"py\"), (\"X\",\"Y\")]\n",
    "    tracks = (first_play or {}).get(\"tracks\") or []\n",
    "    for tr in tracks:\n",
    "        steps = tr.get(\"steps\") or tr.get(\"track_steps\") or []\n",
    "        if not steps:\n",
    "            continue\n",
    "        s0 = steps[0]\n",
    "        for kx, ky in XY_KEYS:\n",
    "            if kx in s0 and ky in s0:\n",
    "                return kx, ky\n",
    "    return \"x\", \"y\"  # Standard\n",
    "\n",
    "def _gather_sample_xy(plays, kx, ky, max_n=5000):\n",
    "    # (x,y)-Werte zur Einheitenerkennung\n",
    "    out = []\n",
    "    for play in plays:\n",
    "        for tr in (play.get(\"tracks\") or []):\n",
    "            for s in (tr.get(\"steps\") or []):\n",
    "                if len(out) >= max_n:\n",
    "                    return out\n",
    "                x = _to_float(s.get(kx)); y = _to_float(s.get(ky))\n",
    "                if x is None or y is None:\n",
    "                    continue\n",
    "                out.append((x,y))\n",
    "    return out\n",
    "\n",
    "def _auto_units(sample_xy):\n",
    "    if FORCE_UNITS in (\"yards\",\"feet\"):\n",
    "        return FORCE_UNITS\n",
    "    if not sample_xy:\n",
    "        return \"yards\"\n",
    "    def score_xy(pairs):\n",
    "        n = min(len(pairs), 2000)\n",
    "        if n == 0:\n",
    "            return 0.0\n",
    "        inb = 0\n",
    "        for i in range(n):\n",
    "            x,y = pairs[i]\n",
    "            if 0 <= x <= FIELD_LEN and 0 <= y <= FIELD_WID:\n",
    "                inb += 1\n",
    "        return inb / n\n",
    "    yards_pairs = sample_xy\n",
    "    feet_pairs  = [(x/3.0, y/3.0) for (x,y) in sample_xy]\n",
    "    sy, sf = score_xy(yards_pairs), score_xy(feet_pairs)\n",
    "    return \"yards\" if sy >= sf else \"feet\"\n",
    "\n",
    "files = sorted(glob.glob(INPUT_GLOB))\n",
    "if not files:\n",
    "    raise FileNotFoundError(f\"Keine Dateien gefunden f√ºr das Muster: {INPUT_GLOB}\")\n",
    "\n",
    "print(f\"Starte Preprocessing: {len(files)} Dateien\")\n",
    "qc_rows = []\n",
    "per_file_outputs = []\n",
    "\n",
    "for i, fp in enumerate(files, 1):\n",
    "    name = os.path.basename(fp)\n",
    "    out_parquet = OUTPUT_DIR / (name.replace(\".json.gz\", \".parquet\"))\n",
    "    print(f\"\\n[{i:03d}/{len(files)}] {name}\")\n",
    "\n",
    "    if out_parquet.exists() and not FORCE_OVERWRITE:\n",
    "        print(f\"  ‚Ü™ Datei existiert bereits, √ºberspringe (FORCE_OVERWRITE={FORCE_OVERWRITE})\")\n",
    "        per_file_outputs.append(out_parquet)\n",
    "        continue\n",
    "\n",
    "    with gzip.open(fp, \"rt\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    plays = data.get(\"plays\") or []\n",
    "    if not plays:\n",
    "        print(\"  Keine Plays gefunden, √ºberspringe\")\n",
    "        continue\n",
    "\n",
    "    # (x,y)-Schl√ºssel und Einheiten\n",
    "    kx, ky = _pick_xy_keys(plays[0])\n",
    "    sample_xy_raw = _gather_sample_xy(plays, kx, ky, max_n=4000)\n",
    "    units = _auto_units(sample_xy_raw)\n",
    "    print(f\" Keys=({kx},{ky})  Einheiten={units}\")\n",
    "\n",
    "    # Z√§hler initialisieren\n",
    "    steps_total = steps_numeric_win = steps_kept_win = 0\n",
    "    drop_cal = drop_oob_gt2 = clip_oob_le2 = 0\n",
    "    rows_acc = defaultdict(lambda: {\n",
    "        \"sx\":0.0,\"sy\":0.0,\"c\":0,\n",
    "        \"pname\":None,\"pos\":None,\"tid\":None,\n",
    "        \"gid\":data.get(\"game_id\"),\n",
    "        \"home\":data.get(\"home_abbr\") or (data.get(\"home_team\",{}) or {}).get(\"nfl_team_id\"),\n",
    "        \"away\":data.get(\"away_abbr\") or (data.get(\"away_team\",{}) or {}).get(\"nfl_team_id\"),\n",
    "        \"off\":None,\"def\":None,\n",
    "        \"q\":None,\"down\":None,\"ytg\":None,\"ptype\":None\n",
    "    })\n",
    "\n",
    "    for play in plays:\n",
    "        puid = play.get(\"play_uuid\")\n",
    "        if not puid:\n",
    "            continue\n",
    "\n",
    "        ltr = bool(play.get(\"offense_left_to_right\", True))\n",
    "        yln = _to_float(play.get(\"play_yardline\"))\n",
    "        if yln is None or not (0.0 <= yln <= 100.0):\n",
    "            # Ung√ºltige Yardline √ºberspringen\n",
    "            continue\n",
    "\n",
    "        off_id = play.get(\"play_offense_team_id\") or play.get(\"offense_team_id\")\n",
    "        def_id = play.get(\"play_defense_team_id\") or play.get(\"defense_team_id\")\n",
    "\n",
    "        meta_by_play[puid] = dict(\n",
    "            ltr=ltr, yln=yln, off=off_id, de=def_id,\n",
    "            q=play.get(\"play_quarter\"),\n",
    "            down=play.get(\"play_down\"),\n",
    "            ytg=play.get(\"play_yards_to_go\"),\n",
    "            ptype=play.get(\"play_type\")\n",
    "        )\n",
    "\n",
    "        for tr in (play.get(\"tracks\") or []):\n",
    "            player = tr.get(\"player\") or tr.get(\"track_player\") or {}\n",
    "            pid = player.get(\"player_id\")\n",
    "            if pid is None:\n",
    "                continue\n",
    "            pname = player.get(\"name\")\n",
    "            ppos  = player.get(\"position_code\")\n",
    "            tid   = tr.get(\"team_id\") or tr.get(\"track_team_id\") or tr.get(\"nfl_team_id\")\n",
    "            steps = tr.get(\"steps\") or tr.get(\"track_steps\") or []\n",
    "            for s in steps:\n",
    "                tss = _to_float(s.get(\"time_since_snap\"))\n",
    "                if tss is None or tss < 0:\n",
    "                    continue\n",
    "                t_sec = int(math.floor(tss))\n",
    "                if t_sec < 0 or t_sec >= WINDOW_SECONDS:\n",
    "                    continue\n",
    "\n",
    "                steps_total += 1\n",
    "\n",
    "                xr = _to_float(s.get(kx)); yr = _to_float(s.get(ky))\n",
    "                if xr is None or yr is None:\n",
    "                    continue\n",
    "\n",
    "                # Einheitstransformation\n",
    "                if units == \"feet\":\n",
    "                    x_raw, y_raw = xr/3.0, yr/3.0\n",
    "                else:\n",
    "                    x_raw, y_raw = xr, yr\n",
    "\n",
    "                steps_numeric_win += 1\n",
    "\n",
    "                # calibration_fault pr√ºfen\n",
    "                cal = s.get(\"calibration_fault\")\n",
    "                if cal is None:\n",
    "                    cal = s.get(\"step_calibration_fault\")\n",
    "                if bool(cal):\n",
    "                    drop_cal += 1\n",
    "                    continue\n",
    "\n",
    "                # OOB-Check vor Orientierung\n",
    "                m = _overshoot_mag(x_raw, y_raw)\n",
    "                if m > OOB_DROP_YARDS:\n",
    "                    drop_oob_gt2 += 1\n",
    "                    continue\n",
    "                if m > 0:\n",
    "                    x_raw, y_raw = _clip_xy(x_raw, y_raw)\n",
    "                    clip_oob_le2 += 1\n",
    "\n",
    "                # Orientierung: X \n",
    "                x = x_raw if ltr else (FIELD_LEN - x_raw)\n",
    "                y = y_raw\n",
    "\n",
    "                play_seen[puid] += 1\n",
    "\n",
    "                # Aggregation pro (play, player, Sekunde)\n",
    "                key = (puid, pid, t_sec)\n",
    "                acc = rows_acc[key]\n",
    "                acc[\"sx\"] += x\n",
    "                acc[\"sy\"] += y\n",
    "                acc[\"c\"]  += 1\n",
    "                if acc[\"pname\"] is None: acc[\"pname\"] = pname\n",
    "                if acc[\"pos\"]   is None: acc[\"pos\"]  = ppos\n",
    "                if acc[\"tid\"]   is None: acc[\"tid\"]  = tid\n",
    "                if acc[\"off\"]   is None: acc[\"off\"]  = off_id\n",
    "                if acc[\"def\"]   is None: acc[\"def\"]  = def_id\n",
    "                if acc[\"q\"]     is None: acc[\"q\"]    = play.get(\"play_quarter\")\n",
    "                if acc[\"down\"]  is None: acc[\"down\"] = play.get(\"play_down\")\n",
    "                if acc[\"ytg\"]   is None: acc[\"ytg\"]  = play.get(\"play_yards_to_go\")\n",
    "                if acc[\"ptype\"] is None: acc[\"ptype\"]= play.get(\"play_type\")\n",
    "\n",
    "                steps_kept_win += 1\n",
    "                play_kept[puid] += \n",
    "\n",
    "    # Spiele mit zu wenigen g√ºltigen Schritten verwerfen\n",
    "    drop_plays = set()\n",
    "    for puid, seen in play_seen.items():\n",
    "        kept = play_kept.get(puid, 0)\n",
    "        share = kept / max(seen, 1)\n",
    "        if share < PLAY_MIN_VALID_SHARE:\n",
    "            drop_plays.add(puid)\n",
    "\n",
    "    print(f\"Steps: total={steps_total:,} | numeric={steps_numeric_win:,} | kept={steps_kept_win:,}\")\n",
    "    print(f\"    - calibration_fault: {drop_cal:,}\")\n",
    "    print(f\"    - OOB >{OOB_DROP_YARDS}yd gedroppt: {drop_oob_gt2:,}\")\n",
    "    print(f\"    - OOB ‚â§{OOB_DROP_YARDS}yd geclippt: {clip_oob_le2:,}\")\n",
    "    print(f\"Plays: total={len(plays)} | gedroppt (<{int(PLAY_MIN_VALID_SHARE*100)}% g√ºltig): {len(drop_plays)}\")\n",
    "\n",
    "    # Ausgabe-Daten erstellen\n",
    "    rows = []\n",
    "    for (puid, pid, t_sec), a in rows_acc.items():\n",
    "        if a[\"c\"] == 0 or puid in drop_plays:\n",
    "            continue\n",
    "        meta = meta_by_play.get(puid, {})\n",
    "        ltr = meta.get(\"ltr\", True)\n",
    "        yln = meta.get(\"yln\", 0.0)\n",
    "\n",
    "        # LOS relativ zur Orientierung\n",
    "        L   = (ENDZONE + yln) if ltr else (110.0 - yln)\n",
    "        rows.append({\n",
    "            \"play_uuid\": puid,\n",
    "            \"player_id\": pid,\n",
    "            \"t_sec\": t_sec,\n",
    "            \"x_norm\": (a[\"sx\"]/a[\"c\"]) - L,   \n",
    "            \"y\": a[\"sy\"]/a[\"c\"],              \n",
    "            \"player_name\": a[\"pname\"],\n",
    "            \"position_code\": a[\"pos\"],\n",
    "            \"team_id\": a[\"tid\"],\n",
    "            \"game_id\": a[\"gid\"],\n",
    "            \"home_abbr\": a[\"home\"],\n",
    "            \"away_abbr\": a[\"away\"],\n",
    "            \"offense_team_id\": a[\"off\"],\n",
    "            \"defense_team_id\": a[\"def\"],\n",
    "            \"play_quarter\": a[\"q\"],\n",
    "            \"play_down\": a[\"down\"],\n",
    "            \"play_yards_to_go\": a[\"ytg\"],\n",
    "            \"play_type\": a[\"ptype\"],\n",
    "            \"play_yardline\": yln,\n",
    "            \"ori\": \"KEEP\" if ltr else \"MIRROR\",\n",
    "            \"units\": units,\n",
    "            \"x_key\": kx, \"y_key\": ky,\n",
    "        })\n",
    "\n",
    "    if rows:\n",
    "        df = pd.DataFrame(rows).sort_values([\"play_uuid\",\"player_id\",\"t_sec\"])\n",
    "        # Einzeldatei speichern\n",
    "        if out_parquet.exists() and not FORCE_OVERWRITE:\n",
    "            print(f\"  Ziel existiert bereits und FORCE_OVERWRITE=False ‚Üí Skip Save: {out_parquet}\")\n",
    "        else:\n",
    "            _save_parquet(df, out_parquet)\n",
    "            per_file_outputs.append(out_parquet)\n",
    "    else:\n",
    "        print(\"  Nichts zu speichern (alle Daten verworfen)\")\n",
    "\n",
    "    qc_rows.append({\n",
    "        \"file\": name,\n",
    "        \"plays_total\": len(plays),\n",
    "        \"plays_dropped\": len(drop_plays),\n",
    "        \"steps_total_4s\": steps_total,\n",
    "        \"steps_numeric_4s\": steps_numeric_win,\n",
    "        \"steps_kept_4s\": steps_kept_win,\n",
    "        \"drop_calibration\": drop_cal,\n",
    "        \"drop_oob_gt2\": drop_oob_gt2,\n",
    "        \"clip_oob_le2\": clip_oob_le2,\n",
    "    })\n",
    "\n",
    "# Gesamt-QC anzeigen\n",
    "df_qc = pd.DataFrame(qc_rows)\n",
    "print(\"\\n Fertig (pro Datei).\")\n",
    "if not df_qc.empty:\n",
    "    try:\n",
    "        from IPython.display import display\n",
    "        display(df_qc.head(10))\n",
    "        display(df_qc[[\"steps_total_4s\",\"steps_numeric_4s\",\"steps_kept_4s\",\"drop_calibration\",\"drop_oob_gt2\",\"clip_oob_le2\"]].sum())\n",
    "    except Exception:\n",
    "        print(df_qc.head(10).to_string(index=False))\n",
    "        sums = df_qc[[\"steps_total_4s\",\"steps_numeric_4s\",\"steps_kept_4s\",\"drop_calibration\",\"drop_oob_gt2\",\"clip_oob_le2\"]].sum()\n",
    "        for k,v in sums.items():\n",
    "            print(f\"  {k}: {int(v):,}\")\n",
    "\n",
    "# Master-Output erstellen (Concat aller Parquets)\n",
    "if REBUILD_MASTER:\n",
    "    print(\"\\n Baue Master‚Ä¶\")\n",
    "    # Alle Parquets im OUTPUT_DIR verwenden\n",
    "    parts = sorted(OUTPUT_DIR.glob(\"*.parquet\"))\n",
    "    if not parts:\n",
    "        print(\"  Keine Teile gefunden ‚Äì Master entf√§llt.\")\n",
    "    else:\n",
    "        dfs = []\n",
    "        for p in parts:\n",
    "            try:\n",
    "                d = pd.read_parquet(p)\n",
    "                # Pr√ºfung der Kernspalten\n",
    "                need = {\"play_uuid\",\"player_id\",\"t_sec\",\"x_norm\",\"y\"}\n",
    "                if not need.issubset(d.columns):\n",
    "                    print(f\"  {p.name}: fehlende Spalten {need - set(d.columns)} ‚Äì Teil √ºberspringen\")\n",
    "                    continue\n",
    "                dfs.append(d)\n",
    "            except Exception as e:\n",
    "                print(f\"  {p.name}: Read-Error {e} ‚Äì Teil √ºberspringen\")\n",
    "\n",
    "        if not dfs:\n",
    "            print(\"  Keine verwertbaren Teile ‚Äì Master entf√§llt.\")\n",
    "        else:\n",
    "            master = pd.concat(dfs, ignore_index=True)\n",
    "            master.sort_values([\"game_id\",\"play_uuid\",\"player_id\",\"t_sec\"], inplace=True)\n",
    "\n",
    "            # Berechne dx, dy, speed pro 1 Hz\n",
    "            grp = [\"game_id\",\"play_uuid\",\"player_id\"]\n",
    "            master[\"dx\"] = master.groupby(grp, observed=True)[\"x_norm\"].diff().fillna(0.0)\n",
    "            master[\"dy\"] = master.groupby(grp, observed=True)[\"y\"].diff().fillna(0.0)\n",
    "            master[\"speed\"] = np.sqrt(master[\"dx\"]**2 + master[\"dy\"]**2)\n",
    "\n",
    "            # Schreibpfad mit Zeitstempel\n",
    "            out_master = _safe_parquet_path(MASTER_OUT_DIR, MASTER_BASENAME, ts=True)\n",
    "            _save_parquet(master, out_master)\n",
    "            print(f\"Master geschrieben ‚Üí {out_master}\")\n",
    "else:\n",
    "    print(\"\\nREBUILD_MASTER=False ‚Äì kein Master erstellt.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9be5e3",
   "metadata": {},
   "source": [
    "merge & mini check "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1caea992",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "try:\n",
    "    from IPython.display import display\n",
    "except Exception:\n",
    "    def display(x): print(x)\n",
    "\n",
    "BASE_DIR = Path(\"/Users/tunahansari/football_ra/out_1hz_clean\")\n",
    "if not BASE_DIR.exists():\n",
    "    BASE_DIR = Path.cwd() / \"out_1hz_clean\"\n",
    "\n",
    "PARQUET_GLOB = str(BASE_DIR / \"*.parquet\")\n",
    "MASTER_OUT = str(BASE_DIR / \"master_1hz_4s.parquet\")\n",
    "\n",
    "FIELD_WID = 53.33\n",
    "T_MIN, T_MAX = 0, 3\n",
    "\n",
    "REQUIRED_COLS = [\n",
    "    \"play_uuid\", \"player_id\", \"t_sec\", \"x_norm\",\n",
    "    \"position_code\", \"track_team_id\", \"offense_team_id\", \"defense_team_id\",\n",
    "    \"play_yardline\", \"play_type\", \"home_abbr\", \"away_abbr\", \"game_id\", \"gsis_play_id\"\n",
    "]\n",
    "\n",
    "ALIASES = {\n",
    "    \"player_id\": [\"player_id\", \"nfl_id\", \"nflId\"],\n",
    "    \"gsis_play_id\": [\"gsis_play_id\", \"play_id\", \"gsisPlayId\"],\n",
    "    \"position_code\": [\"position_code\", \"position\"],\n",
    "    \"track_team_id\": [\"track_team_id\", \"team_id\", \"teamId\", \"team\"],\n",
    "    \"offense_team_id\": [\"offense_team_id\", \"offenseTeamId\", \"offense_team\"],\n",
    "    \"defense_team_id\": [\"defense_team_id\", \"defenseTeamId\", \"defense_team\"],\n",
    "    \"play_yardline\": [\"play_yardline\", \"yardline\", \"yardLine\"],\n",
    "    \"play_type\": [\"play_type\", \"playType\"],\n",
    "    \"home_abbr\": [\"home_abbr\", \"homeTeamAbbr\", \"home_team\"],\n",
    "    \"away_abbr\": [\"away_abbr\", \"awayTeamAbbr\", \"away_team\"],\n",
    "    \"game_id\": [\"game_id\", \"gameId\"],\n",
    "}\n",
    "\n",
    "def ensure_alias_cols(df, required_cols, aliases):\n",
    "    missing = []\n",
    "    for col in required_cols:\n",
    "        if col in df.columns:\n",
    "            continue\n",
    "        if col in (\"x_norm\", \"t_sec\", \"play_uuid\"):\n",
    "            if col not in df.columns:\n",
    "                missing.append(col)\n",
    "            continue\n",
    "        for a in aliases.get(col, []):\n",
    "            if a in df.columns:\n",
    "                df[col] = df[a]\n",
    "                break\n",
    "        else:\n",
    "            missing.append(col)\n",
    "    return df, missing\n",
    "\n",
    "print(\"Suche Parquet-Dateien ...\")\n",
    "files = sorted(glob.glob(PARQUET_GLOB))\n",
    "files = [f for f in files if not os.path.basename(f).startswith(\"master_\")]\n",
    "print(f\"Gefunden: {len(files)} Dateien in {BASE_DIR}\")\n",
    "\n",
    "if not files:\n",
    "    raise FileNotFoundError(f\"Keine Dateien gefunden. Bitte pr√ºfen: {PARQUET_GLOB}\")\n",
    "\n",
    "print(\"\\nBestimme Spaltennamen f√ºr y (step_y vs. y) aus der ersten Datei ...\")\n",
    "probe = pd.read_parquet(files[0])\n",
    "if \"y\" in probe.columns:\n",
    "    Y_COL = \"y\"\n",
    "elif \"step_y\" in probe.columns:\n",
    "    Y_COL = \"step_y\"\n",
    "else:\n",
    "    raise KeyError(\"Weder 'y' noch 'step_y' in den Parquet-Dateien gefunden.\")\n",
    "print(f\"y-Spalte: {Y_COL}\")\n",
    "\n",
    "print(\"\\nLade & merge alle Dateien (das dauert je nach Platte kurz) ...\")\n",
    "dfs = []\n",
    "running_rows = 0\n",
    "for i, fp in enumerate(files, 1):\n",
    "    name = os.path.basename(fp)\n",
    "    df = pd.read_parquet(fp)\n",
    "    df[\"file\"] = name\n",
    "    dfs.append(df)\n",
    "    running_rows += len(df)\n",
    "    if i % 10 == 0 or i == len(files):\n",
    "        print(f\"[{i:03d}/{len(files)}] geladen: {name}  (aktuelle Gesamtzeilen ~ {running_rows:,})\")\n",
    "\n",
    "master = pd.concat(dfs, ignore_index=True)\n",
    "del dfs, probe\n",
    "\n",
    "print(\"\\nMerge fertig.\")\n",
    "print(f\"master.shape = {master.shape[0]:,} Zeilen √ó {master.shape[1]} Spalten\")\n",
    "mem_mb = master.memory_usage(deep=True).sum() / (1024**2)\n",
    "print(f\"gesch√§tzter Speicherbedarf: {mem_mb:.1f} MB\")\n",
    "\n",
    "print(\"\\nMINI-QC startet ...\")\n",
    "\n",
    "print(\"\\nPflichtspalten pr√ºfen ...\")\n",
    "master, missing_after_alias = ensure_alias_cols(master, REQUIRED_COLS, ALIASES)\n",
    "\n",
    "HARD_REQ = {\"play_uuid\", \"player_id\", \"t_sec\", \"x_norm\"}\n",
    "hard_missing = [c for c in HARD_REQ if c not in master.columns]\n",
    "soft_missing = [c for c in missing_after_alias if c not in HARD_REQ]\n",
    "\n",
    "if hard_missing:\n",
    "    print(f\"Harte Pflichtspalten fehlen: {hard_missing}\")\n",
    "    raise KeyError(f\"Pflichtspalten fehlen: {hard_missing}\")\n",
    "if soft_missing:\n",
    "    for c in soft_missing:\n",
    "        print(f\"Hinweis: optionale/Meta-Spalte fehlt: {c}\")\n",
    "print(\"Pflichtspalten ok.\")\n",
    "\n",
    "print(\"\\nt_sec-Check ... (erwartet 0..3)\")\n",
    "t_min, t_max = master[\"t_sec\"].min(), master[\"t_sec\"].max()\n",
    "vals = np.sort(master[\"t_sec\"].unique())\n",
    "share_out_range = ((master[\"t_sec\"] < T_MIN) | (master[\"t_sec\"] > T_MAX)).mean()\n",
    "print(f\"t_sec Werte: min={t_min}, max={t_max}, Unique={vals[:10]}{' ...' if len(vals) > 10 else ''}\")\n",
    "print(f\"Anteil au√üerhalb [{T_MIN},{T_MAX}]: {share_out_range:.4%}\")\n",
    "if share_out_range > 0:\n",
    "    counts_out = master.loc[(master[\"t_sec\"] < T_MIN) | (master[\"t_sec\"] > T_MAX), \"t_sec\"].value_counts().sort_index()\n",
    "    print(\"Werte au√üerhalb Range (Counts):\")\n",
    "    print(counts_out.to_string())\n",
    "\n",
    "print(\"\\ny-Grenzen (0 .. 53.33 yd) ...\")\n",
    "y = pd.to_numeric(master[Y_COL], errors=\"coerce\")\n",
    "oob_low = (y < 0).sum()\n",
    "oob_high = (y > FIELD_WID).sum()\n",
    "oob_share = ((y < 0) | (y > FIELD_WID)).mean()\n",
    "print(f\"y.min={float(np.nanmin(y)):.3f}, y.max={float(np.nanmax(y)):.3f}\")\n",
    "print(f\"OOB y<0: {oob_low:,} | y>{FIELD_WID}: {oob_high:,}  ‚Üí Anteil: {oob_share:.4%}\")\n",
    "if oob_share == 0:\n",
    "    print(\"y liegt vollst√§ndig im Feld (Clip hat gegriffen).\")\n",
    "else:\n",
    "    print(\"Es gibt noch Punkte au√üerhalb ‚Äì ggf. stichprobenartig pr√ºfen.\")\n",
    "\n",
    "print(\"\\nx_norm @ t=0 ...\")\n",
    "t0 = master.loc[master[\"t_sec\"] == 0, \"x_norm\"]\n",
    "t0 = pd.to_numeric(t0, errors=\"coerce\").dropna()\n",
    "if len(t0) > 0:\n",
    "    q = t0.quantile([0.01, 0.25, 0.5, 0.75, 0.99]).to_dict()\n",
    "    mean_, std_ = float(t0.mean()), float(t0.std())\n",
    "    print(f\"count={t0.shape[0]:,} | mean={mean_:.3f} | std={std_:.3f}\")\n",
    "    print(f\"quantiles: 1%={q[0.01]:.3f}, 25%={q[0.25]:.3f}, 50%={q[0.5]:.3f}, 75%={q[0.75]:.3f}, 99%={q[0.99]:.3f}\")\n",
    "    if abs(mean_) <= 0.25:\n",
    "        print(\"LOS-Normalisierung sieht gut aus (Mittelwert ~0 yd).\")\n",
    "    else:\n",
    "        print(\"Mittelwert ist weiter von 0 entfernt als erwartet ‚Äì ggf. LOS-Offset verifizieren.\")\n",
    "else:\n",
    "    print(\"Keine t=0-Zeilen gefunden (unerwartet).\")\n",
    "\n",
    "print(\"\\nZeilen pro Datei (Top 10):\")\n",
    "lines_per_file = master[\"file\"].value_counts().head(10)\n",
    "print(lines_per_file.to_string())\n",
    "\n",
    "print(\"\\nMINI-QC abgeschlossen ‚Äì Daten sind bereit f√ºr RP/CRP/RQA & Clustering.\")\n",
    "\n",
    "SAVE_MASTER = True\n",
    "if SAVE_MASTER:\n",
    "    out_dir = os.path.dirname(MASTER_OUT)\n",
    "    if out_dir and not os.path.exists(out_dir):\n",
    "        os.makedirs(out_dir, exist_ok=True)\n",
    "    master.to_parquet(MASTER_OUT, index=False)\n",
    "    print(f\"\\nMaster-Parquet gespeichert: {MASTER_OUT}\")\n",
    "    print(\"(Beim Weiterarbeiten kannst du direkt dieses File laden)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad9a555",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "MASTER_OUT = \"/Users/tunahansari/football_ra/out_1hz_clean/master_1hz_4s.parquet\"\n",
    "\n",
    "try:\n",
    "    master \n",
    "except NameError:\n",
    "    master = pd.read_parquet(MASTER_OUT)\n",
    "\n",
    "t0 = master.loc[master[\"t_sec\"] == 0, [\"file\",\"play_uuid\",\"x_norm\",\"position_code\"]].copy()\n",
    "t0[\"abs_x0\"] = t0[\"x_norm\"].abs()\n",
    "\n",
    "print(f\"t0 rows: {len(t0):,}\")\n",
    "print(f\"Anteil |x_norm| @t0 > 12 yd: {(t0['abs_x0']>12).mean():.2%}\")\n",
    "\n",
    "print(\"\\nTop-Dateien mit vielen Ausrei√üern (|x_norm|>12yd) @t0:\")\n",
    "print(t0.loc[t0[\"abs_x0\"]>12].groupby(\"file\").size().sort_values(ascending=False).head(15).to_string())\n",
    "\n",
    "print(\"\\nSchlimmste 10 Plays (|x_norm| @t0):\")\n",
    "cols = [\"file\",\"play_uuid\",\"position_code\",\"x_norm\"]\n",
    "print(t0.sort_values(\"abs_x0\", ascending=False)[cols].head(10).to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a578dd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_norm-Korrektur f√ºr Tracking-Daten\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "MASTER_IN  = \"/Users/tunahansari/football_ra/out_1hz_clean/master_1hz_4s.parquet\"\n",
    "MASTER_OUT = \"/Users/tunahansari/football_ra/out_1hz_clean/master_1hz_4s_fix.parquet\"\n",
    "\n",
    "print(\"Lade Master ‚Ä¶\")\n",
    "try:\n",
    "    master  \n",
    "    print(\"   (nutze vorhandenen DataFrame 'master')\")\n",
    "except NameError:\n",
    "    master = pd.read_parquet(MASTER_IN)\n",
    "    print(f\"   geladen: {len(master):,} Zeilen\")\n",
    "\n",
    "# Sicherheit: numerische Typen erzwingen\n",
    "master[\"t_sec\"]  = pd.to_numeric(master[\"t_sec\"], errors=\"coerce\")\n",
    "master[\"x_norm\"] = pd.to_numeric(master[\"x_norm\"], errors=\"coerce\")\n",
    "\n",
    "t0_before = master.loc[master[\"t_sec\"]==0, \"x_norm\"].dropna()\n",
    "share_bad_before = (t0_before.abs() > 12).mean()\n",
    "print(f\"\\nVorher: |x_norm|@t0 > 12 yd = {share_bad_before:.2%}\")\n",
    "print(f\"   t0 count={t0_before.shape[0]:,} | mean={t0_before.mean():.3f} | std={t0_before.std():.3f}\")\n",
    "\n",
    "# offset pro Play berechnen\n",
    "def play_offset(g: pd.DataFrame) -> float:\n",
    "    t0 = g[g[\"t_sec\"]==0]\n",
    "    if t0.empty:\n",
    "        return 0.0\n",
    "    # Offense-Spieler bei t0\n",
    "    off_mask = (t0[\"track_team_id\"] == t0[\"offense_team_id\"])\n",
    "    if off_mask.sum() >= 8:\n",
    "        med = np.nanmedian(t0.loc[off_mask, \"x_norm\"])\n",
    "    else:\n",
    "        # Fallback: alle bei t0 (z.B. wenn Team-IDs fehlen)\n",
    "        med = np.nanmedian(t0[\"x_norm\"])\n",
    "    return float(med) if np.isfinite(med) else 0.0\n",
    "\n",
    "print(\"\\nBerechne Offsets pro play_uuid ‚Ä¶\")\n",
    "offsets = master.groupby(\"play_uuid\", sort=False).apply(play_offset)\n",
    "\n",
    "# Kleine √úbersicht der Offset-Verteilung\n",
    "q = offsets.quantile([0.01,0.25,0.5,0.75,0.99]).to_dict()\n",
    "print(f\"   Offsets quantiles (yd): 1%={q[0.01]:.2f}, 25%={q[0.25]:.2f}, 50%={q[0.5]:.2f}, 75%={q[0.75]:.2f}, 99%={q[0.99]:.2f}\")\n",
    "print(f\"   Anteil |Offset| > 12 yd: {(offsets.abs()>12).mean():.2%}\")\n",
    "\n",
    "# --- Anwenden: x_norm korrigieren ------------------------------------------\n",
    "print(\"\\n Wende Offsets an (x_norm_fix = x_norm - Offset) ‚Ä¶\")\n",
    "master[\"x_norm_fix\"] = master[\"x_norm\"] - master[\"play_uuid\"].map(offsets)\n",
    "\n",
    "# --- Nachher-Diagnose -------------------------------------------------------\n",
    "t0_after = master.loc[master[\"t_sec\"]==0, \"x_norm_fix\"].dropna()\n",
    "share_bad_after = (t0_after.abs() > 12).mean()\n",
    "print(f\"\\nNachher: |x_norm_fix|@t0 > 12 yd = {share_bad_after:.2%}\")\n",
    "print(f\"   t0 count={t0_after.shape[0]:,} | mean={t0_after.mean():.3f} | std={t0_after.std():.3f}\")\n",
    "\n",
    "# Optional: very-bad plays markieren (falls du noch strenger filtern willst)\n",
    "# Ein simples G√ºtekriterium: Nach der Korrektur sollten >=90% der Spieler eines Plays bei t0 innerhalb ¬±12 yd liegen.\n",
    "t0_fix = master.loc[master[\"t_sec\"]==0, [\"play_uuid\",\"x_norm_fix\"]].copy()\n",
    "t0_fix[\"ok\"] = t0_fix[\"x_norm_fix\"].abs() <= 12\n",
    "good_share = t0_fix.groupby(\"play_uuid\")[\"ok\"].mean()\n",
    "bad_plays = good_share[good_share < 0.90].index\n",
    "print(f\"\\nPlays mit fraglicher Korrektur (t0 <90% in ¬±12 yd): {len(bad_plays):,}\")\n",
    "\n",
    "# --- Speichern --------------------------------------------------------------\n",
    "print(\"\\n Speichere Master mit x_norm_fix ‚Ä¶\")\n",
    "Path(MASTER_OUT).parent.mkdir(parents=True, exist_ok=True)\n",
    "master.to_parquet(MASTER_OUT, index=False)\n",
    "print(f\"   geschrieben: {MASTER_OUT}  (Zeilen: {len(master):,})\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c919a275",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE = \"/Users/tunahansari/football_ra/out_1hz_clean\"\n",
    "IN_FIX = f\"{BASE}/master_1hz_4s_fix.parquet\"\n",
    "OUT_REZERO = f\"{BASE}/master_1hz_4s_rezero.parquet\"\n",
    "OUT_BADPLAYS = f\"{BASE}/bad_plays_t0_lt90.csv\"\n",
    "\n",
    "master = pd.read_parquet(IN_FIX)\n",
    "master[\"t_sec\"] = pd.to_numeric(master[\"t_sec\"], errors=\"coerce\")\n",
    "master[\"x_norm_fix\"] = pd.to_numeric(master[\"x_norm_fix\"], errors=\"coerce\")\n",
    "\n",
    "# 1) Globalen Restversatz @t0 entfernen (zentriert Median auf 0)\n",
    "t0_fix = master.loc[master[\"t_sec\"]==0, \"x_norm_fix\"].dropna()\n",
    "global_residual = float(t0_fix.median()) if len(t0_fix) else 0.0\n",
    "print(f\" Globaler Rest-Offset (Median @t0): {global_residual:.3f} yd\")\n",
    "\n",
    "master[\"x_norm_final\"] = master[\"x_norm_fix\"] - global_residual\n",
    "\n",
    "# Diagnose nach Re-Zentrierung\n",
    "t0_final = master.loc[master[\"t_sec\"]==0, \"x_norm_final\"].dropna()\n",
    "share_bad = (t0_final.abs() > 12).mean()\n",
    "print(f\" Nachher-final: |x_norm_final|@t0 > 12 yd = {share_bad:.2%}\")\n",
    "print(f\"   t0 count={t0_final.shape[0]:,} | mean={t0_final.mean():.3f} | std={t0_final.std():.3f} | median={t0_final.median():.3f}\")\n",
    "\n",
    "# 2) Plays mit <90% ok @t0 markieren & Report schreiben\n",
    "t0 = master.loc[master[\"t_sec\"]==0, [\"play_uuid\",\"x_norm_final\",\"file\"]].copy()\n",
    "t0[\"ok\"] = t0[\"x_norm_final\"].abs() <= 12\n",
    "per_play = t0.groupby(\"play_uuid\").agg(\n",
    "    share_ok=(\"ok\", \"mean\"),\n",
    "    n=(\"ok\",\"size\"),\n",
    "    n_ok=(\"ok\",\"sum\")\n",
    ").reset_index()\n",
    "\n",
    "bad_plays = per_play.loc[per_play[\"share_ok\"] < 0.90, \"play_uuid\"]\n",
    "print(f\"Plays mit t0<90% in ¬±12yd: {len(bad_plays):,}\")\n",
    "\n",
    "# Report: welche Dateien / wie stark betroffen\n",
    "bad_report = (\n",
    "    t0[t0[\"play_uuid\"].isin(bad_plays)]\n",
    "    .drop_duplicates(subset=[\"play_uuid\",\"file\"])\n",
    "    .merge(per_play, on=\"play_uuid\", how=\"left\")\n",
    "    .sort_values([\"share_ok\",\"file\"])\n",
    ")\n",
    "Path(OUT_BADPLAYS).parent.mkdir(parents=True, exist_ok=True)\n",
    "bad_report.to_csv(OUT_BADPLAYS, index=False)\n",
    "print(f\" Report gespeichert: {OUT_BADPLAYS} (Zeilen: {len(bad_report):,})\")\n",
    "\n",
    "# 3) x_norm ersetzen & speichern (f√ºr Downstream)\n",
    "master_out = master.drop(columns=[c for c in [\"x_norm\",\"x_norm_fix\"] if c in master.columns]) \\\n",
    "                   .rename(columns={\"x_norm_final\":\"x_norm\"})\n",
    "master_out.to_parquet(OUT_REZERO, index=False)\n",
    "print(f\" geschrieben: {OUT_REZERO}  (Zeilen: {len(master_out):,})\")\n",
    "\n",
    "print(\"\\nAlles fertig. Nutze ab jetzt dieses File f√ºr Clustering/RP/CRP/RQA:\")\n",
    "print(\" ‚Üí\", OUT_REZERO)\n",
    "print(\"Und schau ggf. in den Bad-Play-Report:\")\n",
    "print(\" ‚Üí\", OUT_BADPLAYS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebf7e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- PREP B: Aus Zeitreihen eine Pro-Play-Feature-Tabelle bauen ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "TS_PATH = \"/Users/tunahansari/football_ra/out_1hz_clean/master_1hz_4s_ready.parquet\"   # oder absoluter Pfad\n",
    "TS = pd.read_parquet(TS_PATH)\n",
    "\n",
    "# Spalten wie 'play_uuid' + Zeitreihen (z. B. speed, d_pos, v_rad, x_norm, y ...)\n",
    "def make_features_from_timeseries(df, id_col=\"play_uuid\"):\n",
    "    feats = []\n",
    "    for pid, g in df.groupby(id_col):\n",
    "        row = {id_col: pid, \"n_samples\": len(g)}\n",
    "        # Statistiken f√ºr die Zeitreihe\n",
    "        for col in [\"speed\", \"d_pos\", \"v_rad\", \"x_norm\", \"y\"]:\n",
    "            if col in g.columns:\n",
    "                med = float(g[col].median())\n",
    "                row[f\"{col}_med\"] = med\n",
    "                row[f\"{col}_mad\"] = float((g[col] - med).abs().median())\n",
    "                row[f\"{col}_iqr\"] = float(g[col].quantile(0.75) - g[col].quantile(0.25))\n",
    "                row[f\"{col}_trend_lr\"] = float(np.polyfit(np.arange(len(g)), g[col].to_numpy(), 1)[0]) if len(g) >= 3 else 0.0\n",
    "        feats.append(row)\n",
    "    return pd.DataFrame(feats)\n",
    "\n",
    "FEATURES = make_features_from_timeseries(TS, id_col=\"play_uuid\")\n",
    "print(FEATURES.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2790155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLUSTER-BLOCK \n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "id_col = \"play_uuid\"\n",
    "assert id_col in FEATURES.columns, f\"Spalte '{id_col}' fehlt in FEATURES.\"\n",
    "\n",
    "# 1) Feature-Spalten automatisch w√§hlen (nur numerisch, ohne ID)\n",
    "num_cols = FEATURES.select_dtypes(include=[np.number]).columns.tolist()\n",
    "feature_cols = [c for c in num_cols if c not in [id_col]]\n",
    "if len(feature_cols) < 2:\n",
    "    raise ValueError(\"Zu wenig numerische Feature-Spalten gefunden. Bitte Feature-Build pr√ºfen.\")\n",
    "\n",
    "# 2) Arbeitskopie & NaNs f√ºllen\n",
    "DF = deepcopy(FEATURES[[id_col] + feature_cols]).copy()\n",
    "X = DF[feature_cols].astype(float)\n",
    "X = X.fillna(X.median(numeric_only=True))\n",
    "\n",
    "# 3) Skalieren (+ optional PCA)\n",
    "Xs = StandardScaler().fit_transform(X)\n",
    "use_pca = True\n",
    "Xc = PCA(n_components=0.90, svd_solver=\"full\", random_state=0).fit_transform(Xs) if use_pca else Xs\n",
    "\n",
    "# 4) k per Silhouette (2..8)\n",
    "best = (-np.inf, None, None)\n",
    "for k in range(2, 9):\n",
    "    km = KMeans(n_clusters=k, n_init=20, random_state=0)\n",
    "    lab = km.fit_predict(Xc)\n",
    "    sil = silhouette_score(Xc, lab) if len(set(lab)) > 1 else -np.inf\n",
    "    if sil > best[0]:\n",
    "        best = (sil, k, km)\n",
    "sil, k_best, km_best = best\n",
    "labs_km = km_best.predict(Xc)\n",
    "\n",
    "# 5) Agglomerativ (Ward) @k_best\n",
    "agg = AgglomerativeClustering(n_clusters=k_best, linkage=\"ward\")\n",
    "labs_agg = agg.fit_predict(Xc)\n",
    "\n",
    "# 6) Labels additiv an FEATURES h√§ngen\n",
    "FEATURES = FEATURES.merge(\n",
    "    DF[[id_col]].assign(cl_kmeans=labs_km, cl_agg=labs_agg),\n",
    "    on=id_col, how=\"left\"\n",
    ")\n",
    "\n",
    "print(f\"Clusterzahl (K-Means): k={k_best}, Silhouette={sil:.3f}\")\n",
    "print(FEATURES[[id_col, 'cl_kmeans','cl_agg']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6dda41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "ks, sils = [], []\n",
    "for k in range(2,9):\n",
    "    km = KMeans(n_clusters=k, n_init=20, random_state=0).fit(Xc)\n",
    "    lab = km.labels_\n",
    "    if len(set(lab))>1:\n",
    "        ks.append(k); sils.append(silhouette_score(Xc, lab))\n",
    "print(list(zip(ks, np.round(sils,3))))\n",
    "# Optional: kurzer Plot\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "plt.plot(ks, sils, marker='o')\n",
    "plt.title('Silhouette je k')\n",
    "plt.xlabel('k'); plt.ylabel('Silhouette'); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8f62c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_profile = (FEATURES\n",
    "                   .groupby('cl_kmeans')[feature_cols]\n",
    "                   .median()\n",
    "                   .assign(n=FEATURES.groupby('cl_kmeans').size()))\n",
    "cluster_profile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630117dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "runs = []\n",
    "best = None\n",
    "for eps in (0.3,0.5,0.7,1.0):\n",
    "    for ms in (5,10,20):\n",
    "        db = DBSCAN(eps=eps, min_samples=ms).fit(Xc)\n",
    "        lab = db.labels_\n",
    "        k_eff = len(set(lab)) - (1 if -1 in lab else 0)\n",
    "        noise = (lab == -1).mean()\n",
    "        runs.append((eps, ms, k_eff, round(noise,3)))\n",
    "# pick eine sinnvolle Kombi (z.B. wenig Noise, k_eff 2‚Äì10) und fitten:\n",
    "db = DBSCAN(eps=0.5, min_samples=10).fit(Xc)\n",
    "FEATURES['cl_dbscan'] = db.labels_\n",
    "print('DBSCAN: -1 = Noise, sonst Cluster-ID')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cd724c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "lab = FEATURES['cl_dbscan']\n",
    "vals, cnts = np.unique(lab, return_counts=True)\n",
    "print(dict(zip(vals, cnts)))\n",
    "noise = float((lab == -1).mean())\n",
    "k_eff = len(set(lab)) - (1 if -1 in set(lab) else 0)\n",
    "print(f\"k_eff={k_eff}, Noise={noise:.1%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b63a743",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster-Labels in Dashboard-DF integrieren\n",
    "df = FEATURES.copy()\n",
    "\n",
    "# Vorherige Spalten sichern (f√ºr Merge-Check)\n",
    "cols_before = set(df.columns) - {'cl_kmeans','cl_agg','cl_dbscan'}\n",
    "unchanged = df[sorted(cols_before)].copy()\n",
    "\n",
    "# Neue Cluster-Labels hinzuf√ºgen\n",
    "added = {'cl_kmeans','cl_agg'} & set(df.columns)\n",
    "print(\"Neue Spalten (sollten nur die Cluster-Labels sein):\", added)\n",
    "print(\"Alte Spalten unver√§ndert:\", True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284e818d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "BASE = \"/Users/tunahansari/football_ra/out_1hz_clean\"\n",
    "IN_MASTER = f\"{BASE}/master_1hz_4s_rezero.parquet\"\n",
    "BAD = f\"{BASE}/bad_plays_t0_lt90.csv\"\n",
    "OUT_READY = f\"{BASE}/master_1hz_4s_ready.parquet\"\n",
    "\n",
    "master = pd.read_parquet(IN_MASTER)\n",
    "bad = pd.read_csv(BAD)[\"play_uuid\"].unique()\n",
    "print(\"Bad plays:\", len(bad))\n",
    "\n",
    "clean = master[~master[\"play_uuid\"].isin(bad)].copy()\n",
    "clean.to_parquet(OUT_READY, index=False)\n",
    "print(f\"geschrieben: {OUT_READY}  (Zeilen: {len(clean):,})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4545772",
   "metadata": {},
   "source": [
    "Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3840395",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from dash import Dash, dcc, html, Input, Output, State, dash_table\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from flask_caching import Cache\n",
    "\n",
    "# Clustering\n",
    "from copy import deepcopy\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# ========================\n",
    "# CONFIG\n",
    "# ========================\n",
    "DEFAULT_FEATURES_PATH = \"out_1hz_clean/master_1hz_4s_ready.parquet\"\n",
    "FEATURES_PATH = os.getenv(\"FEATURES_PATH\", DEFAULT_FEATURES_PATH)\n",
    "\n",
    "MAX_HEATMAP_POINTS = int(os.getenv(\"MAX_HEATMAP_POINTS\", 60_000))\n",
    "SPEED_HIST_BINS    = 36\n",
    "RQA_SHOW_MAX_GAMES = 6\n",
    "\n",
    "# RQA Defaults\n",
    "RQA_DEFAULT_RR   = 0.10  # 10 %\n",
    "RQA_DEFAULT_LMIN = 2\n",
    "RQA_DEFAULT_VMIN = 2\n",
    "\n",
    "# RQA ‚Äì Feature-Gewichte & Standardisierung\n",
    "RQA_FEATURE_WEIGHTS = (1.0, 1.0, 0.6)  # speed etwas geringer gewichten\n",
    "RQA_STANDARDIZE     = True             # z-Score je Achse vor Distanz\n",
    "\n",
    "# Limits f√ºr klassische RQA (Performance)\n",
    "RQA_CLASSIC_DEFAULT_MAXPTS = int(os.getenv(\"RQA_CLASSIC_MAXPTS\", 3000))  # Cap auf Matrix-Kantenl√§nge\n",
    "RQA_CLASSIC_DEFAULT_DECIM  = int(os.getenv(\"RQA_CLASSIC_DECIM\", 1))      # jeden k-ten Punkt\n",
    "\n",
    "# ========================\n",
    "# DATA LOADING\n",
    "# ========================\n",
    "NEEDED_COLS = [\n",
    "    \"play_uuid\",\"player_id\",\"t_sec\",\"x_norm\",\"y\",\n",
    "    \"player_name\",\"position_code\",\"team_id\",\"game_id\",\n",
    "    \"home_abbr\",\"away_abbr\",\"offense_team_id\",\"defense_team_id\",\n",
    "    \"play_quarter\",\"play_down\",\"play_yards_to_go\",\"play_type\",\n",
    "    \"dx\",\"dy\",\"speed\",\"heading_deg\"\n",
    "]\n",
    "\n",
    "def _detect_y_col(df: pd.DataFrame) -> str:\n",
    "    if \"y\" in df.columns: return \"y\"\n",
    "    if \"step_y\" in df.columns: return \"step_y\"\n",
    "    raise KeyError(\"Neither 'y' nor 'step_y' found.\")\n",
    "\n",
    "def load_data(path: str) -> tuple[pd.DataFrame, str, dict]:\n",
    "    path = str(path)\n",
    "    if not Path(path).exists():\n",
    "        raise FileNotFoundError(f\"Features file not found: {path}\")\n",
    "\n",
    "    df0 = pd.read_parquet(path, columns=None)\n",
    "    y_col = _detect_y_col(df0)\n",
    "\n",
    "    cols = [c for c in NEEDED_COLS if c in df0.columns]\n",
    "    if y_col not in cols: cols.append(y_col)\n",
    "    if \"x_norm\" not in cols: cols.append(\"x_norm\")\n",
    "    if \"t_sec\" not in cols: cols.append(\"t_sec\")\n",
    "    if \"game_id\" not in cols: cols.append(\"game_id\")\n",
    "    if \"play_uuid\" not in cols: cols.append(\"play_uuid\")\n",
    "    if \"player_id\" not in cols: cols.append(\"player_id\")\n",
    "\n",
    "    df = df0[cols].copy()\n",
    "    del df0\n",
    "\n",
    "    for cat in [\"player_id\",\"player_name\",\"position_code\",\"team_id\",\"game_id\",\n",
    "                \"home_abbr\",\"away_abbr\",\"play_type\",\"play_uuid\"]:\n",
    "        if cat in df.columns:\n",
    "            df[cat] = df[cat].astype(\"category\")\n",
    "\n",
    "    # --- Essentials pr√ºfen + speed on-load erzeugen (1 Hz) ---\n",
    "    need = {\"game_id\",\"play_uuid\",\"player_id\",\"t_sec\",\"x_norm\",y_col}\n",
    "    missing = [c for c in need if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Fehlende Kernspalten im FEATURES_PATH: {missing}\")\n",
    "\n",
    "    # Sort f√ºr stabile Diff-Berechnung (mergesort bewahrt Reihenfolge bei Ties)\n",
    "    df = df.sort_values([\"game_id\",\"play_uuid\",\"player_id\",\"t_sec\"], kind=\"mergesort\")\n",
    "\n",
    "    # dx/dy/speed/heading sicherstellen oder neu berechnen, falls NaNs\n",
    "    grp = [\"game_id\",\"play_uuid\",\"player_id\"]\n",
    "    need_recalc_dx = (\"dx\" not in df.columns) or df[\"dx\"].isna().any()\n",
    "    need_recalc_dy = (\"dy\" not in df.columns) or df[\"dy\"].isna().any()\n",
    "    need_recalc_sp = (\"speed\" not in df.columns) or df[\"speed\"].isna().any()\n",
    "\n",
    "    if need_recalc_dx:\n",
    "        df[\"dx\"] = df.groupby(grp, observed=True)[\"x_norm\"].diff().fillna(0.0)\n",
    "    if need_recalc_dy:\n",
    "        df[\"dy\"] = df.groupby(grp, observed=True)[y_col].diff().fillna(0.0)\n",
    "    if need_recalc_sp or need_recalc_dx or need_recalc_dy:\n",
    "        # 1 Hz ‚Üí Betrag der Schritt√§nderung in yd/s\n",
    "        df[\"speed\"] = np.hypot(df[\"dx\"], df[\"dy\"]).astype(float)\n",
    "\n",
    "    if (\"heading_deg\" not in df.columns) or df[\"heading_deg\"].isna().any():\n",
    "        # atan2(dy, dx) in Grad\n",
    "        df[\"heading_deg\"] = np.degrees(np.arctan2(df[\"dy\"], df[\"dx\"]).astype(float))\n",
    "        df[\"heading_deg\"] = df[\"heading_deg\"].fillna(0.0)\n",
    "\n",
    "    # sch√∂ne Game-Labels\n",
    "    game_labels = {}\n",
    "    if {\"game_id\",\"home_abbr\",\"away_abbr\"}.issubset(df.columns):\n",
    "        gmeta = df.groupby(\"game_id\", observed=True)[[\"home_abbr\",\"away_abbr\"]].first()\n",
    "        for gid, row in gmeta.iterrows():\n",
    "            game_labels[gid] = f\"{row['home_abbr']} vs {row['away_abbr']}  ‚Ä¢  {gid}\"\n",
    "\n",
    "    return df, y_col, game_labels\n",
    "\n",
    "DF, Y_COL, GAME_LABELS = load_data(FEATURES_PATH)\n",
    "DF[\"play_uuid_str\"] = DF[\"play_uuid\"].astype(str)\n",
    "\n",
    "def opt(lst): return [{\"label\": str(v), \"value\": v} for v in lst]\n",
    "\n",
    "positions_all = sorted(map(str, DF[\"position_code\"].dropna().unique().tolist())) if \"position_code\" in DF else []\n",
    "playtypes_all = sorted(map(str, DF[\"play_type\"].dropna().unique().tolist()))    if \"play_type\" in DF else []\n",
    "players_all   = DF[\"player_name\"].dropna().value_counts().head(200).index.tolist() if \"player_name\" in DF else []\n",
    "games_all     = DF[\"game_id\"].dropna().unique().tolist() if \"game_id\" in DF else []\n",
    "\n",
    "# ========================\n",
    "# PLAY-FEATURES & CLUSTER (additiv)\n",
    "# ========================\n",
    "def make_features_from_timeseries(df: pd.DataFrame, id_col=\"play_uuid\", y_col=\"y\"):\n",
    "    feats = []\n",
    "    for pid, g in df.groupby(id_col, observed=True):\n",
    "        # stabil sortieren (Zeit)\n",
    "        gg = g.sort_values(\"t_sec\", kind=\"mergesort\")\n",
    "        row = {id_col: pid, \"n_samples\": int(len(gg))}\n",
    "        for col in [\"x_norm\", y_col, \"speed\"]:\n",
    "            if col in gg.columns:\n",
    "                vals = gg[col].to_numpy(float)\n",
    "                med  = float(np.nanmedian(vals))\n",
    "                mad  = float(np.nanmedian(np.abs(vals - med)))\n",
    "                q75, q25 = np.nanpercentile(vals, 75), np.nanpercentile(vals, 25)\n",
    "                iqr  = float(q75 - q25)\n",
    "                slope = float(np.polyfit(np.arange(len(vals)), vals, 1)[0]) if len(vals) >= 3 else 0.0\n",
    "                base = col if col != y_col else \"y\"\n",
    "                row[f\"{base}_med\"] = med\n",
    "                row[f\"{base}_mad\"] = mad\n",
    "                row[f\"{base}_iqr\"] = iqr\n",
    "                row[f\"{base}_trend_lr\"] = slope\n",
    "        feats.append(row)\n",
    "    return pd.DataFrame(feats)\n",
    "\n",
    "# 1) Pro-Play-Features bauen\n",
    "FEATURES = make_features_from_timeseries(DF, id_col=\"play_uuid\", y_col=Y_COL)\n",
    "\n",
    "# 2) Cluster fitten (Standardisierung + PCA + k per Silhouette)\n",
    "def cluster_fit_add_labels(FEATURES: pd.DataFrame, id_col=\"play_uuid\", use_pca=True, pca_var=0.90):\n",
    "    # Feature-Auswahl: numerisch, ohne ID/Counts/Labels\n",
    "    drop = {'cl_kmeans','cl_agg','cl_dbscan',id_col,'n_samples'}\n",
    "    feature_cols = [c for c in FEATURES.select_dtypes(include=[np.number]).columns if c not in drop]\n",
    "    if len(feature_cols) < 2:\n",
    "        raise ValueError(\"Zu wenig numerische Feature-Spalten f√ºr Clustering.\")\n",
    "    X = FEATURES[feature_cols].astype(float).fillna(FEATURES[feature_cols].median(numeric_only=True))\n",
    "    scaler = StandardScaler()\n",
    "    Xs = scaler.fit_transform(X)\n",
    "    if use_pca:\n",
    "        pca = PCA(n_components=pca_var, svd_solver=\"full\", random_state=0)\n",
    "        Xc = pca.fit_transform(Xs)\n",
    "    else:\n",
    "        pca, Xc = None, Xs\n",
    "\n",
    "    # k per Silhouette (2..8)\n",
    "    best = (-np.inf, None, None)\n",
    "    for k in range(2, 9):\n",
    "        km = KMeans(n_clusters=k, n_init=20, random_state=0)\n",
    "        lab = km.fit_predict(Xc)\n",
    "        sil = silhouette_score(Xc, lab) if len(set(lab)) > 1 else -np.inf\n",
    "        if sil > best[0]:\n",
    "            best = (sil, k, km)\n",
    "    sil, k_best, km_best = best\n",
    "    labs_km = km_best.predict(Xc)\n",
    "\n",
    "    # Agglomerativ (Ward) @ k_best\n",
    "    agg = AgglomerativeClustering(n_clusters=k_best, linkage=\"ward\")\n",
    "    labs_agg = agg.fit_predict(Xc)\n",
    "\n",
    "    # Labels additiv anh√§ngen\n",
    "    OUT = FEATURES.copy()\n",
    "    OUT[\"cl_kmeans\"] = labs_km\n",
    "    OUT[\"cl_agg\"] = labs_agg\n",
    "    meta = {\"k_best\": int(k_best), \"silhouette\": float(sil), \"n_features\": len(feature_cols), \"pca_used\": bool(use_pca), \"pca_var\": float(pca_var)}\n",
    "    return OUT, meta\n",
    "\n",
    "FEATURES, CLUSTER_META = cluster_fit_add_labels(FEATURES, id_col=\"play_uuid\", use_pca=True, pca_var=0.90)\n",
    "\n",
    "# 3) Labels zur√ºck auf DF mergen (additiv, ver√§ndert nichts)\n",
    "DF = DF.merge(FEATURES[[\"play_uuid\",\"cl_kmeans\",\"cl_agg\"]], on=\"play_uuid\", how=\"left\")\n",
    "\n",
    "# Cluster-Options\n",
    "clusters_all = sorted(pd.Series(DF[\"cl_kmeans\"].dropna().unique()).astype(int).tolist()) if \"cl_kmeans\" in DF else []\n",
    "\n",
    "# ========================\n",
    "# APP & CACHE\n",
    "# ========================\n",
    "app = Dash(__name__)\n",
    "app.title = \"Football RA ‚Ä¢ CRP ‚Ä¢ RQA Dashboard\"\n",
    "cache = Cache(app.server, config={\"CACHE_TYPE\": \"SimpleCache\", \"CACHE_DEFAULT_TIMEOUT\": 300})\n",
    "\n",
    "def _key(x):\n",
    "    if x is None: return \"√ò\"\n",
    "    if isinstance(x, (list, tuple)): return tuple(x)\n",
    "    return x\n",
    "\n",
    "@cache.memoize()\n",
    "def filtered_df_cache(positions, playtypes, players, games, clusters, t0, t1, cols_tuple):\n",
    "    q = DF\n",
    "    if positions and \"position_code\" in q:\n",
    "        q = q[q[\"position_code\"].isin(positions)]\n",
    "    if playtypes and \"play_type\" in q:\n",
    "        q = q[q[\"play_type\"].isin(playtypes)]\n",
    "    if players and \"player_name\" in q:\n",
    "        q = q[q[\"player_name\"].isin(players)]\n",
    "    if games and \"game_id\" in q:\n",
    "        q = q[q[\"game_id\"].isin(games)]\n",
    "    if clusters is not None and len(clusters) > 0 and \"cl_kmeans\" in q:\n",
    "        q = q[q[\"cl_kmeans\"].isin(clusters)]\n",
    "    if \"t_sec\" in q:\n",
    "        q = q[(q[\"t_sec\"] >= t0) & (q[\"t_sec\"] <= t1)]\n",
    "    cols = [c for c in list(cols_tuple) if c in q.columns]\n",
    "    return q[cols].copy()\n",
    "\n",
    "def filtered_df(sel, cols):\n",
    "    return filtered_df_cache(\n",
    "        _key(sel.get(\"positions\")), _key(sel.get(\"playtypes\")),\n",
    "        _key(sel.get(\"players\")), _key(sel.get(\"games\")),\n",
    "        _key(sel.get(\"clusters\")),\n",
    "        sel.get(\"t_range\", (0,3))[0], sel.get(\"t_range\", (0,3))[1],\n",
    "        tuple(cols),\n",
    "    )\n",
    "\n",
    "def valid_options_from(df):\n",
    "    return (\n",
    "        sorted(map(str, df[\"position_code\"].dropna().unique().tolist())) if \"position_code\" in df else [],\n",
    "        sorted(map(str, df[\"play_type\"].dropna().unique().tolist()))     if \"play_type\" in df else [],\n",
    "        sorted(map(str, df[\"player_name\"].dropna().unique().tolist()))   if \"player_name\" in df else [],\n",
    "        df[\"game_id\"].dropna().unique().tolist()                         if \"game_id\" in df else [],\n",
    "    )\n",
    "\n",
    "# ========================\n",
    "# LAYOUT\n",
    "# ========================\n",
    "controls = html.Div([\n",
    "    html.Div([html.Label(\"Position(en)\"),\n",
    "              dcc.Dropdown(id=\"positions\", options=opt(positions_all), multi=True,\n",
    "                           placeholder=\"z. B. WR, DB ‚Ä¶\", persistence=True)],\n",
    "             style={\"flex\":1,\"minWidth\":220,\"marginRight\":12}),\n",
    "    html.Div([html.Label(\"Play-Typ(en)\"),\n",
    "              dcc.Dropdown(id=\"play_types\", options=opt(playtypes_all), multi=True,\n",
    "                           placeholder=\"z. B. Pass, Rush ‚Ä¶\", persistence=True)],\n",
    "             style={\"flex\":1,\"minWidth\":220,\"marginRight\":12}),\n",
    "    html.Div([html.Label(\"Spieler\"),\n",
    "              dcc.Dropdown(id=\"players\", options=opt(players_all), multi=True,\n",
    "                           placeholder=\"Spieler w√§hlen ‚Ä¶\", persistence=True)],\n",
    "             style={\"flex\":1,\"minWidth\":260,\"marginRight\":12}),\n",
    "    html.Div([html.Label(\"Spiele\"),\n",
    "              dcc.Dropdown(id=\"games\",\n",
    "                           options=[{\"label\": GAME_LABELS.get(g, str(g)), \"value\": g} for g in games_all],\n",
    "                           multi=True, placeholder=\"Optional Spiele ‚Ä¶\", persistence=True)],\n",
    "             style={\"flex\":1,\"minWidth\":260,\"marginRight\":12}),\n",
    "    html.Div([html.Label(\"Cluster (K-Means)\"),\n",
    "              dcc.Dropdown(id=\"clusters\",\n",
    "                           options=[{\"label\": \"alle\", \"value\": \"__ALL__\"}] + [{\"label\": str(c), \"value\": int(c)} for c in clusters_all],\n",
    "                           multi=True, placeholder=\"Cluster w√§hlen ‚Ä¶\", persistence=True)],\n",
    "             style={\"flex\":1,\"minWidth\":220,\"marginRight\":12}),\n",
    "    html.Div([html.Label(\"t_sec\"),\n",
    "              dcc.RangeSlider(id=\"t_range\", min=0, max=3, step=1, value=[0,3],\n",
    "                              marks={i:str(i) for i in range(4)}, updatemode=\"mouseup\")],\n",
    "             style={\"flex\":1,\"minWidth\":220}),\n",
    "], style={\"display\":\"flex\",\"flexWrap\":\"wrap\",\"gap\":8,\"alignItems\":\"flex-end\",\"marginBottom\":10})\n",
    "\n",
    "app.layout = html.Div([\n",
    "    html.H3(\"Football RA ‚Ä¢ CRP ‚Ä¢ RQA Dashboard\"),\n",
    "    html.Div([html.Span(\"Daten: \"), html.Code(Path(FEATURES_PATH).name),\n",
    "              html.Span(f\"  | Zeilen: {len(DF):,}\", style={\"opacity\": .7, \"marginLeft\": 10})],\n",
    "             style={\"marginBottom\": 8}),\n",
    "    controls,\n",
    "    dcc.Tabs(id=\"tabs\", value=\"tab-overview\", children=[\n",
    "        dcc.Tab(label=\"Overview\", value=\"tab-overview\", children=[\n",
    "            html.Div(id=\"kpi-row\", style={\"display\":\"flex\",\"gap\":12,\"flexWrap\":\"wrap\",\"marginBottom\":8}),\n",
    "            dcc.Graph(id=\"heatmap_xy\",     style={\"height\":\"420px\"}),\n",
    "            dcc.Graph(id=\"profile_means\",  style={\"height\":\"340px\"}),\n",
    "            dcc.Graph(id=\"speed_hist\",     style={\"height\":\"300px\"}),\n",
    "        ]),\n",
    "        dcc.Tab(label=\"CRP (Offense vs Defense)\", value=\"tab-crp\", children=[\n",
    "            dcc.Graph(id=\"crp_chart\", style={\"height\":\"420px\",\"marginTop\":\"10px\"}),\n",
    "            dash_table.DataTable(id=\"crp_table\", page_size=10,\n",
    "                                 style_table={\"overflowX\":\"auto\"},\n",
    "                                 style_cell={\"padding\":\"6px\",\"fontFamily\":\"monospace\",\"fontSize\":12}),\n",
    "        ]),\n",
    "        dcc.Tab(label=\"RQA (pro Spiel ‚Äì illustrativ)\", value=\"tab-rqa\", children=[\n",
    "            html.Div([\n",
    "                html.Div([html.Label(\"Ziel-Recurrence Rate (RR)\"),\n",
    "                          dcc.Slider(id=\"rqa_target_rr\", min=0.02, max=0.15, step=0.005, value=RQA_DEFAULT_RR,\n",
    "                                     marks={0.05:\"5%\",0.1:\"10%\",0.125:\"12.5%\",0.15:\"15%\"})],\n",
    "                         style={\"minWidth\":280,\"marginRight\":16}),\n",
    "                html.Div([html.Label(\"l_min\"),\n",
    "                          dcc.Dropdown(id=\"rqa_lmin\", options=[{\"label\":i,\"value\":i} for i in [2,3,4]],\n",
    "                                       value=RQA_DEFAULT_LMIN, clearable=False)],\n",
    "                         style={\"width\":220,\"marginRight\":16}),\n",
    "                html.Div([html.Label(\"v_min\"),\n",
    "                          dcc.Dropdown(id=\"rqa_vmin\", options=[{\"label\":i,\"value\":i} for i in [2,3,4]],\n",
    "                                       value=RQA_DEFAULT_VMIN, clearable=False)],\n",
    "                         style={\"width\":220,\"marginRight\":16}),\n",
    "                html.Div([html.Label(\" \"), html.Button(\"RQA berechnen\", id=\"rqa_compute\", n_clicks=0, style={\"width\":\"200px\",\"height\":\"38px\"})]),\n",
    "            ], style={\"display\":\"flex\",\"flexWrap\":\"wrap\",\"alignItems\":\"flex-end\",\"gap\":8,\"marginBottom\":8}),\n",
    "            html.Div(id=\"rqa_plots_grid\",\n",
    "                     style={\"display\":\"grid\",\"gridTemplateColumns\":\"repeat(auto-fit, minmax(260px, 1fr))\",\"gap\":\"12px\"}),\n",
    "            dash_table.DataTable(id=\"rqa_table\", page_size=10,\n",
    "                                 style_table={\"overflowX\":\"auto\"},\n",
    "                                 style_cell={\"padding\":\"6px\",\"fontFamily\":\"monospace\",\"fontSize\":12}),\n",
    "            html.Div(id=\"rqa_note\", style={\"opacity\":.7,\"marginTop\":6})\n",
    "        ]),\n",
    "        dcc.Tab(label=\"RQA (klassisch ‚Ä¢ komplette Serie)\", value=\"tab-rqa-classic\", children=[\n",
    "            html.Div([\n",
    "                html.Div([html.Label(\"RR-Modus\"),\n",
    "                          dcc.RadioItems(\n",
    "                              id=\"rqac_rr_mode\",\n",
    "                              options=[\n",
    "                                  {\"label\":\"Dynamisch (Slider)\", \"value\":\"dynamic\"},\n",
    "                                  {\"label\":\"Vorgefertigt (5% / 10% / 15%)\", \"value\":\"preset\"},\n",
    "                              ],\n",
    "                              value=\"dynamic\",\n",
    "                              inline=True\n",
    "                          )],\n",
    "                         style={\"minWidth\":360,\"marginRight\":16}),\n",
    "                html.Div([html.Label(\"Ziel-RR (dynamisch)\"),\n",
    "                          dcc.Slider(id=\"rqac_target_rr\", min=0.02, max=0.15, step=0.005, value=RQA_DEFAULT_RR,\n",
    "                                     marks={0.05:\"5%\",0.10:\"10%\",0.125:\"12.5%\",0.15:\"15%\"})],\n",
    "                         style={\"minWidth\":280,\"marginRight\":16}),\n",
    "                html.Div([html.Label(\"RR (vorgefertigt)\"),\n",
    "                          dcc.Dropdown(id=\"rqac_rr_preset\",\n",
    "                                       options=[{\"label\":\"5%\",\"value\":0.05},\n",
    "                                                {\"label\":\"10%\",\"value\":0.10},\n",
    "                                                {\"label\":\"15%\",\"value\":0.15}],\n",
    "                                       value=RQA_DEFAULT_RR, clearable=False)],\n",
    "                         style={\"width\":180,\"marginRight\":16}),\n",
    "                html.Div([html.Label(\"l_min\"),\n",
    "                          dcc.Dropdown(id=\"rqac_lmin\", options=[{\"label\":i,\"value\":i} for i in [2,3,4,5]],\n",
    "                                       value=RQA_DEFAULT_LMIN, clearable=False)],\n",
    "                         style={\"width\":160,\"marginRight\":16}),\n",
    "                html.Div([html.Label(\"v_min\"),\n",
    "                          dcc.Dropdown(id=\"rqac_vmin\", options=[{\"label\":i,\"value\":i} for i in [2,3,4,5]],\n",
    "                                       value=RQA_DEFAULT_VMIN, clearable=False)],\n",
    "                         style={\"width\":160,\"marginRight\":16}),\n",
    "                html.Div([html.Label(\"Decimation (jeder k-te Punkt)\"),\n",
    "                          dcc.Input(id=\"rqac_decim\", type=\"number\", min=1, step=1, value=RQA_CLASSIC_DEFAULT_DECIM, style={\"width\":\"120px\"})],\n",
    "                         style={\"marginRight\":16}),\n",
    "                html.Div([html.Label(\"Max. Punkte (Cap)\"),\n",
    "                          dcc.Input(id=\"rqac_maxpts\", type=\"number\", min=200, step=100, value=RQA_CLASSIC_DEFAULT_MAXPTS, style={\"width\":\"140px\"})],\n",
    "                         style={\"marginRight\":16}),\n",
    "                html.Div([html.Label(\" \"), html.Button(\"Klassische RQA berechnen\", id=\"rqac_compute\", n_clicks=0, style={\"width\":\"240px\",\"height\":\"38px\"})]),\n",
    "            ], style={\"display\":\"flex\",\"flexWrap\":\"wrap\",\"alignItems\":\"flex-end\",\"gap\":8,\"marginBottom\":8}),\n",
    "            dcc.Graph(id=\"rqac_plot\", style={\"height\":\"560px\"}),\n",
    "            dash_table.DataTable(id=\"rqac_table\", page_size=5,\n",
    "                                 style_table={\"overflowX\":\"auto\"},\n",
    "                                 style_cell={\"padding\":\"6px\",\"fontFamily\":\"monospace\",\"fontSize\":12}),\n",
    "            html.Div(id=\"rqac_note\", style={\"opacity\":.7,\"marginTop\":6})\n",
    "        ]),\n",
    "    ]),\n",
    "])\n",
    "\n",
    "# ========================\n",
    "# FILTER-SYNC (entkoppelt, stabil)\n",
    "# ========================\n",
    "def _options_union_keep_selected(all_values, filtered_values, selected_values):\n",
    "    sel_set = set(map(str, selected_values or []))\n",
    "    vals = set(map(str, filtered_values or [])) | sel_set\n",
    "    if not vals:\n",
    "        vals = set(map(str, all_values or [])) | sel_set\n",
    "    return opt(sorted(vals))\n",
    "\n",
    "@app.callback(\n",
    "    Output(\"positions\",\"options\"), Output(\"play_types\",\"options\"),\n",
    "    Output(\"players\",\"options\"),  Output(\"games\",\"options\"),\n",
    "    Input(\"positions\",\"value\"),   Input(\"play_types\",\"value\"),\n",
    "    Input(\"players\",\"value\"),     Input(\"games\",\"value\"),\n",
    ")\n",
    "def sync_filters(pos_v, pt_v, pl_v, gm_v):\n",
    "    sel_for_pos = dict(positions=[], playtypes=pt_v or [], players=pl_v or [], games=gm_v or [], clusters=[], t_range=(0,3))\n",
    "    q_pos = filtered_df(sel_for_pos, [\"position_code\"])\n",
    "    pos_vals = q_pos[\"position_code\"].dropna().unique().tolist() if \"position_code\" in q_pos else positions_all\n",
    "    pos_opts = _options_union_keep_selected(positions_all, pos_vals, pos_v)\n",
    "\n",
    "    sel_for_pt  = dict(positions=pos_v or [], playtypes=[], players=pl_v or [], games=gm_v or [], clusters=[], t_range=(0,3))\n",
    "    q_pt = filtered_df(sel_for_pt, [\"play_type\"])\n",
    "    pt_vals = q_pt[\"play_type\"].dropna().unique().tolist() if \"play_type\" in q_pt else playtypes_all\n",
    "    pt_opts = _options_union_keep_selected(playtypes_all, pt_vals, pt_v)\n",
    "\n",
    "    sel_for_pl  = dict(positions=pos_v or [], playtypes=pt_v or [], players=[], games=gm_v or [], clusters=[], t_range=(0,3))\n",
    "    q_pl = filtered_df(sel_for_pl, [\"player_name\"])\n",
    "    pl_vals = q_pl[\"player_name\"].dropna().unique().tolist() if \"player_name\" in q_pl else players_all\n",
    "    pl_opts = _options_union_keep_selected(players_all, pl_vals, pl_v)\n",
    "\n",
    "    sel_for_gm  = dict(positions=pos_v or [], playtypes=pt_v or [], players=pl_v or [], games=[], clusters=[], t_range=(0,3))\n",
    "    q_gm = filtered_df(sel_for_gm, [\"game_id\"])\n",
    "    gm_vals = q_gm[\"game_id\"].dropna().unique().tolist() if \"game_id\" in q_gm else games_all\n",
    "    gm_opts = [{\"label\": GAME_LABELS.get(g, str(g)), \"value\": g} for g in sorted(gm_vals, key=lambda x: str(x))]\n",
    "\n",
    "    return pos_opts, pt_opts, pl_opts, gm_opts\n",
    "\n",
    "# ========================\n",
    "# OVERVIEW CALLBACK\n",
    "# ========================\n",
    "@app.callback(\n",
    "    Output(\"kpi-row\",\"children\"), Output(\"heatmap_xy\",\"figure\"),\n",
    "    Output(\"profile_means\",\"figure\"), Output(\"speed_hist\",\"figure\"),\n",
    "    Input(\"positions\",\"value\"), Input(\"play_types\",\"value\"),\n",
    "    Input(\"players\",\"value\"), Input(\"games\",\"value\"), Input(\"clusters\",\"value\"), Input(\"t_range\",\"value\"),\n",
    ")\n",
    "def update_overview(pos_v, pt_v, pl_v, gm_v, cl_v, tr_v):\n",
    "    # Cluster-Value normalisieren\n",
    "    cl_v_norm = [] if not cl_v else [c for c in cl_v if c != \"__ALL__\"]\n",
    "    sel = dict(positions=pos_v or [], playtypes=pt_v or [], players=pl_v or [], games=gm_v or [], clusters=cl_v_norm, t_range=tuple(tr_v or (0,3)))\n",
    "\n",
    "    q = filtered_df(sel, [\"play_uuid\",\"player_id\",\"game_id\",\"t_sec\",\"x_norm\",Y_COL,\"speed\",\"cl_kmeans\"])\n",
    "    def k(label, val):\n",
    "        return html.Div([html.Div(label, style={\"fontSize\":12,\"opacity\":.7}),\n",
    "                         html.Div(f\"{val}\", style={\"fontSize\":22,\"fontWeight\":600})],\n",
    "                        style={\"padding\":\"8px 12px\",\"border\":\"1px solid #eee\",\"borderRadius\":8,\"minWidth\":140})\n",
    "    kpis = [k(\"Zeilen\", f\"{len(q):,}\"),\n",
    "            k(\"Unique Plays\", q[\"play_uuid\"].nunique()),\n",
    "            k(\"Unique Spieler\", q[\"player_id\"].nunique()),\n",
    "            k(\"Unique Spiele\", q[\"game_id\"].nunique())]\n",
    "    # Cluster-Meta\n",
    "    if CLUSTER_META:\n",
    "        kpis.append(k(\"K-Means k\", CLUSTER_META.get(\"k_best\", \"‚Äî\")))\n",
    "        kpis.append(k(\"Silhouette\", f\"{CLUSTER_META.get('silhouette', float('nan')):.3f}\"))\n",
    "\n",
    "    h = q\n",
    "    if len(h) > MAX_HEATMAP_POINTS: h = h.sample(MAX_HEATMAP_POINTS, random_state=42)\n",
    "    hm = px.density_heatmap(h, x=\"x_norm\", y=Y_COL, nbinsx=60, nbinsy=27, histnorm=\"\")\n",
    "    hm.update_layout(title=\"Dichte: x_norm vs. y (gesampelt)\")\n",
    "    hm.update_yaxes(scaleanchor=\"x\", scaleratio=53.33/120)\n",
    "\n",
    "    g = q.groupby(\"t_sec\").agg(mean_x=(\"x_norm\",\"mean\"), mean_y=(Y_COL,\"mean\"), mean_v=(\"speed\",\"mean\")).reset_index()\n",
    "    prof = go.Figure()\n",
    "    for col, name in [(\"mean_x\",\"mean x_norm\"),(\"mean_y\",\"mean y\"),(\"mean_v\",\"mean speed (yd/s)\")]:\n",
    "        prof.add_trace(go.Scatter(x=g[\"t_sec\"], y=g[col], mode=\"lines+markers\", name=name))\n",
    "    prof.update_layout(title=\"Mittelwerte je t_sec\", xaxis_title=\"t_sec\", yaxis_title=\"Wert\")\n",
    "\n",
    "    hist = px.histogram(q, x=\"speed\", nbins=SPEED_HIST_BINS, title=\"Geschwindigkeit (yd/s)\")\n",
    "    return kpis, hm, prof, hist\n",
    "\n",
    "# ========================\n",
    "# CRP CALLBACK (mit korrekter Off/Def-Trennung)\n",
    "# ========================\n",
    "def crp_off_vs_def(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Korrekte Trennung:\n",
    "      Offense = rows mit team_id == offense_team_id\n",
    "      Defense = rows mit team_id == defense_team_id\n",
    "    Aggregation: Mittelwerte je t_sec (x_norm, y, speed)\n",
    "    \"\"\"\n",
    "    needed = {\"t_sec\",\"x_norm\",Y_COL,\"speed\",\"team_id\",\"offense_team_id\",\"defense_team_id\"}\n",
    "    if not needed.issubset(df.columns):\n",
    "        # Fallback: keine Trennung m√∂glich\n",
    "        gg = df.groupby(\"t_sec\").agg(x=(\"x_norm\",\"mean\"), y=(Y_COL,\"mean\"), v=(\"speed\",\"mean\")).reset_index()\n",
    "        out = gg.rename(columns={\"x\":\"off_x\",\"y\":\"off_y\",\"v\":\"off_v\"})\n",
    "        out[\"def_x\"] = out[\"off_x\"]; out[\"def_y\"] = out[\"off_y\"]; out[\"def_v\"] = out[\"off_v\"]\n",
    "        out[\"dx\"] = 0.0; out[\"dy\"] = 0.0; out[\"dv\"] = 0.0\n",
    "        return out\n",
    "\n",
    "    is_off = df[\"team_id\"].astype(\"Int64\") == df[\"offense_team_id\"].astype(\"Int64\")\n",
    "    is_def = df[\"team_id\"].astype(\"Int64\") == df[\"defense_team_id\"].astype(\"Int64\")\n",
    "\n",
    "    off = df[is_off]\n",
    "    de  = df[is_def]\n",
    "\n",
    "    g_off = off.groupby(\"t_sec\").agg(x=(\"x_norm\",\"mean\"), y=(Y_COL,\"mean\"), v=(\"speed\",\"mean\")).add_prefix(\"off_\").reset_index()\n",
    "    g_def = de .groupby(\"t_sec\").agg(x=(\"x_norm\",\"mean\"), y=(Y_COL,\"mean\"), v=(\"speed\",\"mean\")).add_prefix(\"def_\").reset_index()\n",
    "\n",
    "    out = pd.merge(g_off, g_def, on=\"t_sec\", how=\"outer\").sort_values(\"t_sec\")\n",
    "    out[[\"off_x\",\"off_y\",\"off_v\",\"def_x\",\"def_y\",\"def_v\"]] = out[\n",
    "        [\"off_x\",\"off_y\",\"off_v\",\"def_x\",\"def_y\",\"def_v\"]\n",
    "    ].ffill().bfill()\n",
    "\n",
    "    out[\"dx\"] = out[\"off_x\"] - out[\"def_x\"]\n",
    "    out[\"dy\"] = out[\"off_y\"] - out[\"def_y\"]\n",
    "    out[\"dv\"] = out[\"off_v\"] - out[\"def_v\"]\n",
    "    return out\n",
    "\n",
    "@app.callback(\n",
    "    Output(\"crp_chart\",\"figure\"), Output(\"crp_table\",\"columns\"), Output(\"crp_table\",\"data\"),\n",
    "    Input(\"positions\",\"value\"), Input(\"play_types\",\"value\"),\n",
    "    Input(\"players\",\"value\"), Input(\"games\",\"value\"), Input(\"clusters\",\"value\"), Input(\"t_range\",\"value\"),\n",
    ")\n",
    "def update_crp(pos_v, pt_v, pl_v, gm_v, cl_v, tr_v):\n",
    "    cl_v_norm = [] if not cl_v else [c for c in cl_v if c != \"__ALL__\"]\n",
    "    sel = dict(positions=pos_v or [], playtypes=pt_v or [], players=pl_v or [], games=gm_v or [], clusters=cl_v_norm, t_range=tuple(tr_v or (0,3)))\n",
    "    q = filtered_df(sel, [\"t_sec\",\"x_norm\",Y_COL,\"speed\",\"team_id\",\"offense_team_id\",\"defense_team_id\"])\n",
    "    comp = crp_off_vs_def(q)\n",
    "\n",
    "    fig = go.Figure()\n",
    "    for col, name in [(\"off_x\",\"Offense mean x\"),(\"def_x\",\"Defense mean x\"),(\"dx\",\"Œîx (Off-Def)\")]:\n",
    "        fig.add_trace(go.Scatter(x=comp[\"t_sec\"], y=comp[col], mode=\"lines+markers\",\n",
    "                                 name=name, line=dict(dash=\"dash\") if col.startswith(\"d\") else None))\n",
    "    for col, name in [(\"off_v\",\"Offense mean v\"),(\"def_v\",\"Defense mean v\"),(\"dv\",\"Œîv (Off-Def)\")]:\n",
    "        fig.add_trace(go.Scatter(x=comp[\"t_sec\"], y=comp[col], mode=\"lines+markers\",\n",
    "                                 name=name, line=dict(dash=\"dash\") if col.startswith(\"d\") else None))\n",
    "    fig.update_layout(title=\"CRP: Offense vs Defense (x & v)\", xaxis_title=\"t_sec\")\n",
    "\n",
    "    cols = [{\"name\": c, \"id\": c} for c in comp.columns]\n",
    "    data = comp.round(3).to_dict(\"records\")\n",
    "    return fig, cols, data\n",
    "\n",
    "# ========================\n",
    "# RQA HELFER\n",
    "# ========================\n",
    "def pairwise_dist(A: np.ndarray, w: np.ndarray):\n",
    "    \"\"\"Gewichtete euklidische Distanzmatrix f√ºr NxD-Array A mit Gewichten w (D,).\"\"\"\n",
    "    A = np.asarray(A, float)\n",
    "    w = np.asarray(w, float).reshape(1, -1)\n",
    "    diff = A[:, None, :] - A[None, :, :]\n",
    "    return np.sqrt((diff**2 * w).sum(axis=2))\n",
    "\n",
    "def recurrence_matrix(arr: np.ndarray, target_rr: float, w=(1.0,1.0,1.0), standardize: bool = True):\n",
    "    A = np.asarray(arr, float)\n",
    "    if standardize:\n",
    "        mu = A.mean(axis=0, keepdims=True)\n",
    "        sd = A.std(axis=0, keepdims=True) + 1e-9\n",
    "        A = (A - mu) / sd\n",
    "    w = np.asarray(w, float)\n",
    "    D = pairwise_dist(A, w)\n",
    "    tri = D[np.triu_indices_from(D, k=1)]\n",
    "    if len(tri) == 0:\n",
    "        eps = 0.0\n",
    "        return (D <= eps).astype(int), float(eps)\n",
    "    eps = float(np.quantile(tri, target_rr))\n",
    "    return (D <= eps).astype(int), eps\n",
    "\n",
    "def rqa_metrics(R: np.ndarray, l_min=2, v_min=2):\n",
    "    N = R.size\n",
    "    RR = R.sum() / N if N > 0 else 0.0\n",
    "\n",
    "    # Diagonale Linien\n",
    "    diag_lengths = []\n",
    "    for k in range(-(R.shape[0]-1), R.shape[0]):\n",
    "        d = np.diag(R, k)\n",
    "        if d.size == 0: continue\n",
    "        run = 0\n",
    "        for val in d:\n",
    "            if val == 1: run += 1\n",
    "            else:\n",
    "                if run >= l_min: diag_lengths.append(run)\n",
    "                run = 0\n",
    "        if run >= l_min: diag_lengths.append(run)\n",
    "\n",
    "    DET  = (sum(diag_lengths) / R.sum()) if R.sum() > 0 and diag_lengths else 0.0\n",
    "    Lmax = max(diag_lengths) if diag_lengths else 0\n",
    "    L    = float(np.mean(diag_lengths)) if diag_lengths else 0.0\n",
    "    if diag_lengths:\n",
    "        _, cnts = np.unique(diag_lengths, return_counts=True)\n",
    "        p = cnts / cnts.sum()\n",
    "        ENTR = float(-(p * np.log(p + 1e-12)).sum())\n",
    "    else:\n",
    "        ENTR = 0.0\n",
    "\n",
    "    # Vertikale Linien\n",
    "    vert_lengths = []\n",
    "    for j in range(R.shape[1]):\n",
    "        col = R[:, j]\n",
    "        run = 0\n",
    "        for val in col:\n",
    "            if val == 1: run += 1\n",
    "            else:\n",
    "                if run >= v_min: vert_lengths.append(run)\n",
    "                run = 0\n",
    "        if run >= v_min: vert_lengths.append(run)\n",
    "\n",
    "    LAM = (sum(vert_lengths) / R.sum()) if R.sum() > 0 and vert_lengths else 0.0\n",
    "    TT  = float(np.mean(vert_lengths)) if vert_lengths else 0.0\n",
    "    if vert_lengths:\n",
    "        _, cnts_v = np.unique(vert_lengths, return_counts=True)\n",
    "        p_v = cnts_v / cnts_v.sum()\n",
    "        ENTR_V = float(-(p_v * np.log(p_v + 1e-12)).sum())\n",
    "    else:\n",
    "        ENTR_V = 0.0\n",
    "\n",
    "    return dict(RR=RR, DET=DET, L=L, Lmax=Lmax, ENTR=ENTR, LAM=LAM, TT=TT, ENTR_V=ENTR_V)\n",
    "\n",
    "def game_traj(df_game: pd.DataFrame, y_col: str):\n",
    "    # 4 Punkte je Spiel (0..3s) ‚Äì Mittelwerte √ºber Spieler\n",
    "    g = df_game.groupby(\"t_sec\")[[\"x_norm\", y_col, \"speed\"]].mean().reindex([0,1,2,3])\n",
    "    g = g.ffill().bfill()\n",
    "    return g.to_numpy(float)\n",
    "\n",
    "def build_full_series(df: pd.DataFrame, y_col: str, decim: int, maxpts: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Durchgehende 1 Hz-Serie aus der aktuellen Auswahl:\n",
    "    sortiert nach game_id ‚Üí play_uuid ‚Üí t_sec, pro Zeitstempel Mittelwert √ºber Spieler.\n",
    "    \"\"\"\n",
    "    if df.empty:\n",
    "        return np.empty((0, 3), float)\n",
    "\n",
    "    cols = [\"game_id\",\"play_uuid\",\"t_sec\",\"x_norm\",y_col,\"speed\"]\n",
    "    q = df[cols].copy().sort_values([\"game_id\",\"play_uuid\",\"t_sec\"])\n",
    "    q = q.groupby([\"game_id\",\"play_uuid\",\"t_sec\"], observed=True)[[\"x_norm\", y_col, \"speed\"]].mean().reset_index()\n",
    "\n",
    "    series = q[[\"x_norm\", y_col, \"speed\"]].to_numpy(float)\n",
    "    if decim is None or decim < 1: decim = 1\n",
    "    series = series[::decim]\n",
    "\n",
    "    if maxpts and series.shape[0] > maxpts:\n",
    "        series = series[:maxpts, :]\n",
    "\n",
    "    series = pd.DataFrame(series, columns=[\"x\",\"y\",\"v\"]).ffill().bfill().to_numpy(float)\n",
    "    return series\n",
    "\n",
    "# ========================\n",
    "# RQA CALLBACK (pro Spiel)\n",
    "# ========================\n",
    "# RQA pro Spiel\n",
    "@app.callback(\n",
    "    Output(\"rqa_plots_grid\",\"children\"),\n",
    "    Output(\"rqa_table\",\"columns\"),\n",
    "    Output(\"rqa_table\",\"data\"),\n",
    "    Output(\"rqa_note\",\"children\"),\n",
    "    Input(\"rqa_compute\",\"n_clicks\"),\n",
    "    State(\"positions\",\"value\"), State(\"play_types\",\"value\"),\n",
    "    State(\"players\",\"value\"),  State(\"games\",\"value\"),\n",
    "    State(\"t_range\",\"value\"),\n",
    "    State(\"rqa_target_rr\",\"value\"), State(\"rqa_lmin\",\"value\"), State(\"rqa_vmin\",\"value\"),\n",
    "    State(\"clusters\",\"value\"),                    \n",
    "    prevent_initial_call=True\n",
    ")\n",
    "def compute_rqa(n_clicks, pos_v, pt_v, pl_v, gm_v, tr_v, target_rr, l_min, v_min, cl_v): \n",
    "    cl_v_norm = [] if not cl_v else [c for c in cl_v if c != \"__ALL__\"]\n",
    "    sel = dict(positions=pos_v or [], playtypes=pt_v or [], players=pl_v or [],\n",
    "               games=gm_v or [], clusters=cl_v_norm, t_range=tuple(tr_v or (0,3)))\n",
    "    q = filtered_df(sel, [\"game_id\",\"t_sec\",\"x_norm\",Y_COL,\"speed\",\"home_abbr\",\"away_abbr\",\"cl_kmeans\"])\n",
    "\n",
    "    if q.empty:\n",
    "        return [html.Div(\"Keine Daten f√ºr die aktuelle Auswahl.\", style={\"padding\":\"8px\"})], [], [], \"\"\n",
    "    games = list(q[\"game_id\"].dropna().unique())\n",
    "    games_show = games[:RQA_SHOW_MAX_GAMES]\n",
    "    plots, rows = [], []\n",
    "    for gid in games_show:\n",
    "        qg = q[q[\"game_id\"] == gid]\n",
    "        arr = game_traj(qg, Y_COL)\n",
    "        R, eps = recurrence_matrix(arr, target_rr=target_rr, w=RQA_FEATURE_WEIGHTS, standardize=RQA_STANDARDIZE)\n",
    "\n",
    "        mets = rqa_metrics(R, l_min=l_min, v_min=v_min)\n",
    "        title_txt = GAME_LABELS.get(gid, str(gid))\n",
    "        fig = px.imshow(R, origin=\"lower\", aspect=\"equal\",\n",
    "                        labels=dict(x=\"t (s)\", y=\"t (s)\"),\n",
    "                        color_continuous_scale=[\"#ffffff\", \"#000000\"])\n",
    "        fig.update_layout(title=f\"RQA ‚Äî {title_txt}  (Œµ‚âà{eps:.3f}, RR‚âà{target_rr:.1%})\",\n",
    "                          margin=dict(l=30,r=10,t=46,b=30))\n",
    "        plots.append(dcc.Graph(figure=fig, style={\"height\":\"260px\"}))\n",
    "        rows.append({\n",
    "            \"game_id\": gid,\n",
    "            \"match\": GAME_LABELS.get(gid, str(gid)),\n",
    "            \"RR\": round(mets[\"RR\"], 4),\n",
    "            \"DET\": round(mets[\"DET\"], 4),\n",
    "            \"L\": round(mets[\"L\"], 3),\n",
    "            \"Lmax\": int(mets[\"Lmax\"]),\n",
    "            \"ENTR\": round(mets[\"ENTR\"], 3),\n",
    "            \"LAM\": round(mets[\"LAM\"], 4),\n",
    "            \"TT\": round(mets[\"TT\"], 3),\n",
    "            \"ENTR_V\": round(mets[\"ENTR_V\"], 3),\n",
    "            \"epsilon_auto\": round(eps, 4)\n",
    "        })\n",
    "    cols = [{\"name\": c, \"id\": c} for c in [\"game_id\",\"match\",\"RR\",\"DET\",\"L\",\"Lmax\",\"ENTR\",\"LAM\",\"TT\",\"ENTR_V\",\"epsilon_auto\"]]\n",
    "    note = (\n",
    "    f\"Es werden max. {RQA_SHOW_MAX_GAMES} Spiele visualisiert. \"\n",
    "    f\"Button gedr√ºckt: {n_clicks}. \"\n",
    "    \"Hinweis: Die pro-Spiel-Ansicht ist explorativ/illustrativ (nur 4 Zeitpunkte @ 1 Hz).\"\n",
    "    )\n",
    "\n",
    "    return plots, cols, rows, note\n",
    "\n",
    "# ========================\n",
    "# RQA CALLBACK (klassisch ‚Ä¢ komplette Serie)\n",
    "# ========================\n",
    "# RQA klassisch\n",
    "@app.callback(\n",
    "    Output(\"rqac_plot\",\"figure\"),\n",
    "    Output(\"rqac_table\",\"columns\"),\n",
    "    Output(\"rqac_table\",\"data\"),\n",
    "    Output(\"rqac_note\",\"children\"),\n",
    "    Input(\"rqac_compute\",\"n_clicks\"),\n",
    "    State(\"positions\",\"value\"), State(\"play_types\",\"value\"),\n",
    "    State(\"players\",\"value\"),  State(\"games\",\"value\"),\n",
    "    State(\"t_range\",\"value\"),\n",
    "    State(\"rqac_rr_mode\",\"value\"),\n",
    "    State(\"rqac_target_rr\",\"value\"), State(\"rqac_rr_preset\",\"value\"),\n",
    "    State(\"rqac_lmin\",\"value\"), State(\"rqac_vmin\",\"value\"),\n",
    "    State(\"rqac_decim\",\"value\"), State(\"rqac_maxpts\",\"value\"),\n",
    "    State(\"clusters\",\"value\"),                     # ‚Üê NEU\n",
    "    prevent_initial_call=True\n",
    ")\n",
    "def compute_rqa_classic(n_clicks, pos_v, pt_v, pl_v, gm_v, tr_v,\n",
    "                        rr_mode, target_rr, rr_preset, l_min, v_min, decim, maxpts, cl_v):  # ‚Üê NEU\n",
    "    cl_v_norm = [] if not cl_v else [c for c in cl_v if c != \"__ALL__\"]\n",
    "    sel = dict(positions=pos_v or [], playtypes=pt_v or [], players=pl_v or [],\n",
    "               games=gm_v or [], clusters=cl_v_norm, t_range=tuple(tr_v or (0,3)))\n",
    "    q = filtered_df(sel, [\"game_id\",\"play_uuid\",\"t_sec\",\"x_norm\",Y_COL,\"speed\",\"cl_kmeans\"])\n",
    "    if q.empty:\n",
    "        return go.Figure().update_layout(title=\"Keine Daten f√ºr die aktuelle Auswahl.\"), [], [], \"\"\n",
    "    print(\"RQA classic ‚Äî Cluster-Filter:\", cl_v_norm or \"alle\", \"| rows:\", len(q))  # Debug\n",
    "    arr = build_full_series(q, Y_COL, decim=decim or RQA_CLASSIC_DEFAULT_DECIM,\n",
    "                            maxpts=maxpts or RQA_CLASSIC_DEFAULT_MAXPTS)\n",
    "    ...\n",
    "\n",
    "    if q.empty:\n",
    "        empty_fig = go.Figure().update_layout(title=\"Keine Daten f√ºr die aktuelle Auswahl.\")\n",
    "        return empty_fig, [], [], \"\"\n",
    "\n",
    "    arr = build_full_series(q, Y_COL, decim=decim or RQA_CLASSIC_DEFAULT_DECIM, maxpts=maxpts or RQA_CLASSIC_DEFAULT_MAXPTS)\n",
    "    if arr.shape[0] < 2:\n",
    "        empty_fig = go.Figure().update_layout(title=\"Zu wenige Punkte f√ºr RQA.\")\n",
    "        return empty_fig, [], [], \"Hinweis: Serie hat < 2 Punkte.\"\n",
    "\n",
    "    rr_val = float(target_rr if rr_mode == \"dynamic\" else rr_preset)\n",
    "    R, eps = recurrence_matrix(arr, target_rr=rr_val, w=RQA_FEATURE_WEIGHTS, standardize=RQA_STANDARDIZE)\n",
    "    mets = rqa_metrics(R, l_min=int(l_min), v_min=int(v_min))\n",
    "\n",
    "    fig = px.imshow(R, origin=\"lower\", aspect=\"equal\",\n",
    "                    labels=dict(x=\"time in s\", y=\"time in s\"),\n",
    "                    color_continuous_scale=[\"#ffffff\", \"#000000\"])\n",
    "    fig.update_coloraxes(showscale=True)\n",
    "    fig.update_layout(\n",
    "        title=f\"Klassische RQA ‚Äî komplette Serie (Œµ‚âà{eps:.3f}, RR‚âà{rr_val:.1%}, N={R.shape[0]})\",\n",
    "        margin=dict(l=40,r=20,t=60,b=40)\n",
    "    )\n",
    "\n",
    "    cols = [{\"name\": c, \"id\": c} for c in [\"N\",\"RR\",\"DET\",\"L\",\"Lmax\",\"ENTR\",\"LAM\",\"TT\",\"ENTR_V\",\"epsilon_auto\",\"rr_mode\",\"decim\",\"maxpts\"]]\n",
    "    data = [{\n",
    "        \"N\": int(R.shape[0]),\n",
    "        \"RR\": round(mets[\"RR\"], 4),\n",
    "        \"DET\": round(mets[\"DET\"], 4),\n",
    "        \"L\": round(mets[\"L\"], 3),\n",
    "        \"Lmax\": int(mets[\"Lmax\"]),\n",
    "        \"ENTR\": round(mets[\"ENTR\"], 3),\n",
    "        \"LAM\": round(mets[\"LAM\"], 4),\n",
    "        \"TT\": round(mets[\"TT\"], 3),\n",
    "        \"ENTR_V\": round(mets[\"ENTR_V\"], 3),\n",
    "        \"epsilon_auto\": round(eps, 4),\n",
    "        \"rr_mode\": rr_mode,\n",
    "        \"decim\": int(decim or RQA_CLASSIC_DEFAULT_DECIM),\n",
    "        \"maxpts\": int(maxpts or RQA_CLASSIC_DEFAULT_MAXPTS),\n",
    "    }]\n",
    "\n",
    "    note = (\"Serie wird aus der aktuellen Filterauswahl gebildet: geordnete Folge aller ausgew√§hlten Plays (1 Hz), \"\n",
    "            \"pro Zeitstempel Mittelwert √ºber gefilterte Spieler. RR kann dynamisch (Slider) \"\n",
    "            \"oder als vorgefertigte Variante (5 % / 10 % / 15 %) gew√§hlt werden. \"\n",
    "            \"‚ÄöDecimation‚Äò reduziert die L√§nge (jeder k-te Punkt), ‚ÄöMax. Punkte‚Äò deckelt die Kantenl√§nge der Matrix.\")\n",
    "    return fig, cols, data, note\n",
    "\n",
    "# ========================\n",
    "# MAIN\n",
    "# ========================\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"\\n Loaded:\")\n",
    "    print(\"  path:\", FEATURES_PATH)\n",
    "    print(\"  DF shape:\", DF.shape)\n",
    "    print(\"  DF columns:\", DF.columns.tolist())\n",
    "    print(\"  has speed?\", (\"speed\" in DF.columns) and not pd.isna(DF[\"speed\"]).any())\n",
    "    print(\"\\nClustering:\")\n",
    "    print(\"  PCA used:\", CLUSTER_META.get(\"pca_used\"))\n",
    "    print(\"  PCA variance retained:\", CLUSTER_META.get(\"pca_var\"))\n",
    "    print(\"  n_features (for clustering):\", CLUSTER_META.get(\"n_features\"))\n",
    "    print(\"  k_best:\", CLUSTER_META.get(\"k_best\"))\n",
    "    print(\"  silhouette:\", f\"{CLUSTER_META.get('silhouette'):.3f}\")\n",
    "    app.run(debug=False, port=int(os.getenv(\"PORT\", 8050)), use_reloader=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5a9a12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Address already in use\n",
      "Port 8050 is in use by another program. Either identify and stop that program, or start the server with a different port.\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[31mSystemExit\u001b[39m\u001b[31m:\u001b[39m 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tunahansari/football_ra/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py:3707: UserWarning:\n",
      "\n",
      "To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from dash import Dash, dcc, html, Input, Output, State, dash_table\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from flask_caching import Cache\n",
    "\n",
    "# Clustering\n",
    "from copy import deepcopy\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# ========================\n",
    "# CONFIG\n",
    "# ========================\n",
    "DEFAULT_FEATURES_PATH = \"out_1hz_clean/master_1hz_4s_ready.parquet\"\n",
    "FEATURES_PATH = os.getenv(\"FEATURES_PATH\", DEFAULT_FEATURES_PATH)\n",
    "\n",
    "MAX_HEATMAP_POINTS = int(os.getenv(\"MAX_HEATMAP_POINTS\", 60_000))\n",
    "SPEED_HIST_BINS    = 36\n",
    "RQA_SHOW_MAX_GAMES = 6\n",
    "\n",
    "# RQA Defaults\n",
    "RQA_DEFAULT_RR   = 0.10  # 10 %\n",
    "RQA_DEFAULT_LMIN = 2\n",
    "RQA_DEFAULT_VMIN = 2\n",
    "\n",
    "# RQA ‚Äì Feature-Gewichte & Standardisierung\n",
    "RQA_FEATURE_WEIGHTS = (1.0, 1.0, 0.6)  # speed etwas geringer gewichten\n",
    "RQA_STANDARDIZE     = True             # z-Score je Achse vor Distanz\n",
    "\n",
    "# Limits f√ºr klassische RQA (Performance)\n",
    "RQA_CLASSIC_DEFAULT_MAXPTS = int(os.getenv(\"RQA_CLASSIC_MAXPTS\", 3000))  # Cap auf Matrix-Kantenl√§nge\n",
    "RQA_CLASSIC_DEFAULT_DECIM  = int(os.getenv(\"RQA_CLASSIC_DECIM\", 1))      # jeden k-ten Punkt\n",
    "\n",
    "# ========================\n",
    "# DATA LOADING\n",
    "# ========================\n",
    "NEEDED_COLS = [\n",
    "    \"play_uuid\",\"player_id\",\"t_sec\",\"x_norm\",\"y\",\n",
    "    \"player_name\",\"position_code\",\"team_id\",\"game_id\",\n",
    "    \"home_abbr\",\"away_abbr\",\"offense_team_id\",\"defense_team_id\",\n",
    "    \"play_quarter\",\"play_down\",\"play_yards_to_go\",\"play_type\",\n",
    "    \"dx\",\"dy\",\"speed\",\"heading_deg\"\n",
    "]\n",
    "\n",
    "def _detect_y_col(df: pd.DataFrame) -> str:\n",
    "    if \"y\" in df.columns: return \"y\"\n",
    "    if \"step_y\" in df.columns: return \"step_y\"\n",
    "    raise KeyError(\"Neither 'y' nor 'step_y' found.\")\n",
    "\n",
    "def load_data(path: str) -> tuple[pd.DataFrame, str, dict]:\n",
    "    path = str(path)\n",
    "    if not Path(path).exists():\n",
    "        raise FileNotFoundError(f\"Features file not found: {path}\")\n",
    "\n",
    "    df0 = pd.read_parquet(path, columns=None)\n",
    "    y_col = _detect_y_col(df0)\n",
    "\n",
    "    cols = [c for c in NEEDED_COLS if c in df0.columns]\n",
    "    if y_col not in cols: cols.append(y_col)\n",
    "    if \"x_norm\" not in cols: cols.append(\"x_norm\")\n",
    "    if \"t_sec\" not in cols: cols.append(\"t_sec\")\n",
    "    if \"game_id\" not in cols: cols.append(\"game_id\")\n",
    "    if \"play_uuid\" not in cols: cols.append(\"play_uuid\")\n",
    "    if \"player_id\" not in cols: cols.append(\"player_id\")\n",
    "\n",
    "    df = df0[cols].copy()\n",
    "    del df0\n",
    "\n",
    "    for cat in [\"player_id\",\"player_name\",\"position_code\",\"team_id\",\"game_id\",\n",
    "                \"home_abbr\",\"away_abbr\",\"play_type\",\"play_uuid\"]:\n",
    "        if cat in df.columns:\n",
    "            df[cat] = df[cat].astype(\"category\")\n",
    "\n",
    "    need = {\"game_id\",\"play_uuid\",\"player_id\",\"t_sec\",\"x_norm\",y_col}\n",
    "    missing = [c for c in need if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Fehlende Kernspalten im FEATURES_PATH: {missing}\")\n",
    "\n",
    "    # Sort f√ºr stabile Diff-Berechnung (mergesort bewahrt Reihenfolge bei Ties)\n",
    "    df = df.sort_values([\"game_id\",\"play_uuid\",\"player_id\",\"t_sec\"], kind=\"mergesort\")\n",
    "\n",
    "    # dx/dy/speed/heading sicherstellen oder neu berechnen, falls NaNs\n",
    "    grp = [\"game_id\",\"play_uuid\",\"player_id\"]\n",
    "    need_recalc_dx = (\"dx\" not in df.columns) or df[\"dx\"].isna().any()\n",
    "    need_recalc_dy = (\"dy\" not in df.columns) or df[\"dy\"].isna().any()\n",
    "    need_recalc_sp = (\"speed\" not in df.columns) or df[\"speed\"].isna().any()\n",
    "\n",
    "    if need_recalc_dx:\n",
    "        df[\"dx\"] = df.groupby(grp, observed=True)[\"x_norm\"].diff().fillna(0.0)\n",
    "    if need_recalc_dy:\n",
    "        df[\"dy\"] = df.groupby(grp, observed=True)[y_col].diff().fillna(0.0)\n",
    "    if need_recalc_sp or need_recalc_dx or need_recalc_dy:\n",
    "        # 1 Hz ‚Üí Betrag der Schritt√§nderung in yd/s\n",
    "        df[\"speed\"] = np.hypot(df[\"dx\"], df[\"dy\"]).astype(float)\n",
    "\n",
    "    if (\"heading_deg\" not in df.columns) or df[\"heading_deg\"].isna().any():\n",
    "        # atan2(dy, dx) in Grad\n",
    "        df[\"heading_deg\"] = np.degrees(np.arctan2(df[\"dy\"], df[\"dx\"]).astype(float))\n",
    "        df[\"heading_deg\"] = df[\"heading_deg\"].fillna(0.0)\n",
    "\n",
    "    # sch√∂ne Game-Labels\n",
    "    game_labels = {}\n",
    "    if {\"game_id\",\"home_abbr\",\"away_abbr\"}.issubset(df.columns):\n",
    "        gmeta = df.groupby(\"game_id\", observed=True)[[\"home_abbr\",\"away_abbr\"]].first()\n",
    "        for gid, row in gmeta.iterrows():\n",
    "            game_labels[gid] = f\"{row['home_abbr']} vs {row['away_abbr']}  ‚Ä¢  {gid}\"\n",
    "\n",
    "    return df, y_col, game_labels\n",
    "\n",
    "DF, Y_COL, GAME_LABELS = load_data(FEATURES_PATH)\n",
    "DF[\"play_uuid_str\"] = DF[\"play_uuid\"].astype(str)\n",
    "\n",
    "def opt(lst): return [{\"label\": str(v), \"value\": v} for v in lst]\n",
    "\n",
    "positions_all = sorted(map(str, DF[\"position_code\"].dropna().unique().tolist())) if \"position_code\" in DF else []\n",
    "playtypes_all = sorted(map(str, DF[\"play_type\"].dropna().unique().tolist()))    if \"play_type\" in DF else []\n",
    "players_all   = DF[\"player_name\"].dropna().value_counts().head(200).index.tolist() if \"player_name\" in DF else []\n",
    "games_all     = DF[\"game_id\"].dropna().unique().tolist() if \"game_id\" in DF else []\n",
    "\n",
    "# ========================\n",
    "# PLAY-FEATURES & CLUSTER\n",
    "# ========================\n",
    "def make_features_from_timeseries(df: pd.DataFrame, id_col=\"play_uuid\", y_col=\"y\"):\n",
    "    feats = []\n",
    "    for pid, g in df.groupby(id_col, observed=True):\n",
    "        # stabil sortieren (Zeit)\n",
    "        gg = g.sort_values(\"t_sec\", kind=\"mergesort\")\n",
    "        row = {id_col: pid, \"n_samples\": int(len(gg))}\n",
    "        for col in [\"x_norm\", y_col, \"speed\"]:\n",
    "            if col in gg.columns:\n",
    "                vals = gg[col].to_numpy(float)\n",
    "                med  = float(np.nanmedian(vals))\n",
    "                mad  = float(np.nanmedian(np.abs(vals - med)))\n",
    "                q75, q25 = np.nanpercentile(vals, 75), np.nanpercentile(vals, 25)\n",
    "                iqr  = float(q75 - q25)\n",
    "                slope = float(np.polyfit(np.arange(len(vals)), vals, 1)[0]) if len(vals) >= 3 else 0.0\n",
    "                base = col if col != y_col else \"y\"\n",
    "                row[f\"{base}_med\"] = med\n",
    "                row[f\"{base}_mad\"] = mad\n",
    "                row[f\"{base}_iqr\"] = iqr\n",
    "                row[f\"{base}_trend_lr\"] = slope\n",
    "        feats.append(row)\n",
    "    return pd.DataFrame(feats)\n",
    "\n",
    "# 1) Pro-Play-Features bauen\n",
    "FEATURES = make_features_from_timeseries(DF, id_col=\"play_uuid\", y_col=Y_COL)\n",
    "\n",
    "# 2) Cluster fitten (Standardisierung + PCA + k per Silhouette)\n",
    "def cluster_fit_add_labels(FEATURES: pd.DataFrame, id_col=\"play_uuid\", use_pca=True, pca_var=0.90):\n",
    "    # Feature-Auswahl: numerisch, ohne ID/Counts/Labels\n",
    "    drop = {'cl_kmeans','cl_agg','cl_dbscan',id_col,'n_samples'}\n",
    "    feature_cols = [c for c in FEATURES.select_dtypes(include=[np.number]).columns if c not in drop]\n",
    "    if len(feature_cols) < 2:\n",
    "        raise ValueError(\"Zu wenig numerische Feature-Spalten f√ºr Clustering.\")\n",
    "    X = FEATURES[feature_cols].astype(float).fillna(FEATURES[feature_cols].median(numeric_only=True))\n",
    "    scaler = StandardScaler()\n",
    "    Xs = scaler.fit_transform(X)\n",
    "    if use_pca:\n",
    "        pca = PCA(n_components=pca_var, svd_solver=\"full\", random_state=0)\n",
    "        Xc = pca.fit_transform(Xs)\n",
    "    else:\n",
    "        pca, Xc = None, Xs\n",
    "\n",
    "    # k per Silhouette (2..8)\n",
    "    best = (-np.inf, None, None)\n",
    "    for k in range(2, 9):\n",
    "        km = KMeans(n_clusters=k, n_init=20, random_state=0)\n",
    "        lab = km.fit_predict(Xc)\n",
    "        sil = silhouette_score(Xc, lab) if len(set(lab)) > 1 else -np.inf\n",
    "        if sil > best[0]:\n",
    "            best = (sil, k, km)\n",
    "    sil, k_best, km_best = best\n",
    "    labs_km = km_best.predict(Xc)\n",
    "\n",
    "    # Agglomerative Clustering (Ward-Linkage)\n",
    "    agg = AgglomerativeClustering(n_clusters=k_best, linkage=\"ward\")\n",
    "    labs_agg = agg.fit_predict(Xc)\n",
    "\n",
    "    # Labels hinzuf√ºgen\n",
    "    OUT = FEATURES.copy()\n",
    "    OUT[\"cl_kmeans\"] = labs_km\n",
    "    OUT[\"cl_agg\"] = labs_agg\n",
    "    meta = {\"k_best\": int(k_best), \"silhouette\": float(sil), \"n_features\": len(feature_cols), \"pca_used\": bool(use_pca), \"pca_var\": float(pca_var)}\n",
    "    return OUT, meta\n",
    "\n",
    "FEATURES, CLUSTER_META = cluster_fit_add_labels(FEATURES, id_col=\"play_uuid\", use_pca=True, pca_var=0.90)\n",
    "\n",
    "# 3) Labels zur√ºck auf DF mergen (additiv, ver√§ndert nichts)\n",
    "DF = DF.merge(FEATURES[[\"play_uuid\",\"cl_kmeans\",\"cl_agg\"]], on=\"play_uuid\", how=\"left\")\n",
    "\n",
    "# Cluster-Options\n",
    "clusters_all = sorted(pd.Series(DF[\"cl_kmeans\"].dropna().unique()).astype(int).tolist()) if \"cl_kmeans\" in DF else []\n",
    "\n",
    "# ========================\n",
    "# APP & CACHE\n",
    "# ========================\n",
    "app = Dash(__name__)\n",
    "app.title = \"Football RA ‚Ä¢ CRP ‚Ä¢ RQA Dashboard\"\n",
    "cache = Cache(app.server, config={\"CACHE_TYPE\": \"SimpleCache\", \"CACHE_DEFAULT_TIMEOUT\": 300})\n",
    "\n",
    "def _key(x):\n",
    "    if x is None: return \"√ò\"\n",
    "    if isinstance(x, (list, tuple)): return tuple(x)\n",
    "    return x\n",
    "\n",
    "@cache.memoize()\n",
    "def filtered_df_cache(positions, playtypes, players, games, clusters, t0, t1, cols_tuple):\n",
    "    q = DF\n",
    "    if positions and \"position_code\" in q:\n",
    "        q = q[q[\"position_code\"].isin(positions)]\n",
    "    if playtypes and \"play_type\" in q:\n",
    "        q = q[q[\"play_type\"].isin(playtypes)]\n",
    "    if players and \"player_name\" in q:\n",
    "        q = q[q[\"player_name\"].isin(players)]\n",
    "    if games and \"game_id\" in q:\n",
    "        q = q[q[\"game_id\"].isin(games)]\n",
    "    if clusters is not None and len(clusters) > 0 and \"cl_kmeans\" in q:\n",
    "        q = q[q[\"cl_kmeans\"].isin(clusters)]\n",
    "    if \"t_sec\" in q:\n",
    "        q = q[(q[\"t_sec\"] >= t0) & (q[\"t_sec\"] <= t1)]\n",
    "    cols = [c for c in list(cols_tuple) if c in q.columns]\n",
    "    return q[cols].copy()\n",
    "\n",
    "def filtered_df(sel, cols):\n",
    "    return filtered_df_cache(\n",
    "        _key(sel.get(\"positions\")), _key(sel.get(\"playtypes\")),\n",
    "        _key(sel.get(\"players\")), _key(sel.get(\"games\")),\n",
    "        _key(sel.get(\"clusters\")),\n",
    "        sel.get(\"t_range\", (0,3))[0], sel.get(\"t_range\", (0,3))[1],\n",
    "        tuple(cols),\n",
    "    )\n",
    "\n",
    "def valid_options_from(df):\n",
    "    return (\n",
    "        sorted(map(str, df[\"position_code\"].dropna().unique().tolist())) if \"position_code\" in df else [],\n",
    "        sorted(map(str, df[\"play_type\"].dropna().unique().tolist()))     if \"play_type\" in df else [],\n",
    "        sorted(map(str, df[\"player_name\"].dropna().unique().tolist()))   if \"player_name\" in df else [],\n",
    "        df[\"game_id\"].dropna().unique().tolist()                         if \"game_id\" in df else [],\n",
    "    )\n",
    "\n",
    "# ========================\n",
    "# LAYOUT\n",
    "# ========================\n",
    "controls = html.Div([\n",
    "    html.Div([html.Label(\"Position(en)\"),\n",
    "              dcc.Dropdown(id=\"positions\", options=opt(positions_all), multi=True,\n",
    "                           placeholder=\"z. B. WR, DB ‚Ä¶\", persistence=True)],\n",
    "             style={\"flex\":1,\"minWidth\":220,\"marginRight\":12}),\n",
    "    html.Div([html.Label(\"Play-Typ(en)\"),\n",
    "              dcc.Dropdown(id=\"play_types\", options=opt(playtypes_all), multi=True,\n",
    "                           placeholder=\"z. B. Pass, Rush ‚Ä¶\", persistence=True)],\n",
    "             style={\"flex\":1,\"minWidth\":220,\"marginRight\":12}),\n",
    "    html.Div([html.Label(\"Spieler\"),\n",
    "              dcc.Dropdown(id=\"players\", options=opt(players_all), multi=True,\n",
    "                           placeholder=\"Spieler w√§hlen ‚Ä¶\", persistence=True)],\n",
    "             style={\"flex\":1,\"minWidth\":260,\"marginRight\":12}),\n",
    "    html.Div([html.Label(\"Spiele\"),\n",
    "              dcc.Dropdown(id=\"games\",\n",
    "                           options=[{\"label\": GAME_LABELS.get(g, str(g)), \"value\": g} for g in games_all],\n",
    "                           multi=True, placeholder=\"Optional Spiele ‚Ä¶\", persistence=True)],\n",
    "             style={\"flex\":1,\"minWidth\":260,\"marginRight\":12}),\n",
    "    html.Div([html.Label(\"Cluster (K-Means)\"),\n",
    "              dcc.Dropdown(id=\"clusters\",\n",
    "                           options=[{\"label\": \"alle\", \"value\": \"__ALL__\"}] + [{\"label\": str(c), \"value\": int(c)} for c in clusters_all],\n",
    "                           multi=True, placeholder=\"Cluster w√§hlen ‚Ä¶\", persistence=True)],\n",
    "             style={\"flex\":1,\"minWidth\":220,\"marginRight\":12}),\n",
    "    html.Div([html.Label(\"t_sec\"),\n",
    "              dcc.RangeSlider(id=\"t_range\", min=0, max=3, step=1, value=[0,3],\n",
    "                              marks={i:str(i) for i in range(4)}, updatemode=\"mouseup\")],\n",
    "             style={\"flex\":1,\"minWidth\":220}),\n",
    "], style={\"display\":\"flex\",\"flexWrap\":\"wrap\",\"gap\":8,\"alignItems\":\"flex-end\",\"marginBottom\":10})\n",
    "\n",
    "app.layout = html.Div([\n",
    "    html.H3(\"Football RA ‚Ä¢ CRP ‚Ä¢ RQA Dashboard\"),\n",
    "    html.Div([html.Span(\"Daten: \"), html.Code(Path(FEATURES_PATH).name),\n",
    "              html.Span(f\"  | Zeilen: {len(DF):,}\", style={\"opacity\": .7, \"marginLeft\": 10})],\n",
    "             style={\"marginBottom\": 8}),\n",
    "    controls,\n",
    "    dcc.Tabs(id=\"tabs\", value=\"tab-overview\", children=[\n",
    "        dcc.Tab(label=\"Overview\", value=\"tab-overview\", children=[\n",
    "            html.Div(id=\"kpi-row\", style={\"display\":\"flex\",\"gap\":12,\"flexWrap\":\"wrap\",\"marginBottom\":8}),\n",
    "            dcc.Graph(id=\"heatmap_xy\",     style={\"height\":\"420px\"}),\n",
    "            dcc.Graph(id=\"profile_means\",  style={\"height\":\"340px\"}),\n",
    "            dcc.Graph(id=\"speed_hist\",     style={\"height\":\"300px\"}),\n",
    "        ]),\n",
    "        dcc.Tab(label=\"CRP (Offense vs Defense)\", value=\"tab-crp\", children=[\n",
    "            dcc.Graph(id=\"crp_chart\", style={\"height\":\"420px\",\"marginTop\":\"10px\"}),\n",
    "            dash_table.DataTable(id=\"crp_table\", page_size=10,\n",
    "                                 style_table={\"overflowX\":\"auto\"},\n",
    "                                 style_cell={\"padding\":\"6px\",\"fontFamily\":\"monospace\",\"fontSize\":12}),\n",
    "        ]),\n",
    "        dcc.Tab(label=\"RQA (pro Spiel ‚Äì illustrativ)\", value=\"tab-rqa\", children=[\n",
    "            html.Div([\n",
    "                html.Div([html.Label(\"Ziel-Recurrence Rate (RR)\"),\n",
    "                          dcc.Slider(id=\"rqa_target_rr\", min=0.02, max=0.15, step=0.005, value=RQA_DEFAULT_RR,\n",
    "                                     marks={0.05:\"5%\",0.1:\"10%\",0.125:\"12.5%\",0.15:\"15%\"})],\n",
    "                         style={\"minWidth\":280,\"marginRight\":16}),\n",
    "                html.Div([html.Label(\"l_min\"),\n",
    "                          dcc.Dropdown(id=\"rqa_lmin\", options=[{\"label\":i,\"value\":i} for i in [2,3,4]],\n",
    "                                       value=RQA_DEFAULT_LMIN, clearable=False)],\n",
    "                         style={\"width\":220,\"marginRight\":16}),\n",
    "                html.Div([html.Label(\"v_min\"),\n",
    "                          dcc.Dropdown(id=\"rqa_vmin\", options=[{\"label\":i,\"value\":i} for i in [2,3,4]],\n",
    "                                       value=RQA_DEFAULT_VMIN, clearable=False)],\n",
    "                         style={\"width\":220,\"marginRight\":16}),\n",
    "                html.Div([html.Label(\" \"), html.Button(\"RQA berechnen\", id=\"rqa_compute\", n_clicks=0, style={\"width\":\"200px\",\"height\":\"38px\"})]),\n",
    "            ], style={\"display\":\"flex\",\"flexWrap\":\"wrap\",\"alignItems\":\"flex-end\",\"gap\":8,\"marginBottom\":8}),\n",
    "            html.Div(id=\"rqa_plots_grid\",\n",
    "                     style={\"display\":\"grid\",\"gridTemplateColumns\":\"repeat(auto-fit, minmax(260px, 1fr))\",\"gap\":\"12px\"}),\n",
    "            dash_table.DataTable(id=\"rqa_table\", page_size=10,\n",
    "                                 style_table={\"overflowX\":\"auto\"},\n",
    "                                 style_cell={\"padding\":\"6px\",\"fontFamily\":\"monospace\",\"fontSize\":12}),\n",
    "            html.Div(id=\"rqa_note\", style={\"opacity\":.7,\"marginTop\":6})\n",
    "        ]),\n",
    "        dcc.Tab(label=\"RQA (klassisch ‚Ä¢ komplette Serie)\", value=\"tab-rqa-classic\", children=[\n",
    "            html.Div([\n",
    "                html.Div([html.Label(\"RR-Modus\"),\n",
    "                          dcc.RadioItems(\n",
    "                              id=\"rqac_rr_mode\",\n",
    "                              options=[\n",
    "                                  {\"label\":\"Dynamisch (Slider)\", \"value\":\"dynamic\"},\n",
    "                                  {\"label\":\"Vorgefertigt (5% / 10% / 15%)\", \"value\":\"preset\"},\n",
    "                              ],\n",
    "                              value=\"dynamic\",\n",
    "                              inline=True\n",
    "                          )],\n",
    "                         style={\"minWidth\":360,\"marginRight\":16}),\n",
    "                html.Div([html.Label(\"Ziel-RR (dynamisch)\"),\n",
    "                          dcc.Slider(id=\"rqac_target_rr\", min=0.02, max=0.15, step=0.005, value=RQA_DEFAULT_RR,\n",
    "                                     marks={0.05:\"5%\",0.10:\"10%\",0.125:\"12.5%\",0.15:\"15%\"})],\n",
    "                         style={\"minWidth\":280,\"marginRight\":16}),\n",
    "                html.Div([html.Label(\"RR (vorgefertigt)\"),\n",
    "                          dcc.Dropdown(id=\"rqac_rr_preset\",\n",
    "                                       options=[{\"label\":\"5%\",\"value\":0.05},\n",
    "                                                {\"label\":\"10%\",\"value\":0.10},\n",
    "                                                {\"label\":\"15%\",\"value\":0.15}],\n",
    "                                       value=RQA_DEFAULT_RR, clearable=False)],\n",
    "                         style={\"width\":180,\"marginRight\":16}),\n",
    "                html.Div([html.Label(\"l_min\"),\n",
    "                          dcc.Dropdown(id=\"rqac_lmin\", options=[{\"label\":i,\"value\":i} for i in [2,3,4,5]],\n",
    "                                       value=RQA_DEFAULT_LMIN, clearable=False)],\n",
    "                         style={\"width\":160,\"marginRight\":16}),\n",
    "                html.Div([html.Label(\"v_min\"),\n",
    "                          dcc.Dropdown(id=\"rqac_vmin\", options=[{\"label\":i,\"value\":i} for i in [2,3,4,5]],\n",
    "                                       value=RQA_DEFAULT_VMIN, clearable=False)],\n",
    "                         style={\"width\":160,\"marginRight\":16}),\n",
    "                html.Div([html.Label(\"Decimation (jeder k-te Punkt)\"),\n",
    "                          dcc.Input(id=\"rqac_decim\", type=\"number\", min=1, step=1, value=RQA_CLASSIC_DEFAULT_DECIM, style={\"width\":\"120px\"})],\n",
    "                         style={\"marginRight\":16}),\n",
    "                html.Div([html.Label(\"Max. Punkte (Cap)\"),\n",
    "                          dcc.Input(id=\"rqac_maxpts\", type=\"number\", min=200, step=100, value=RQA_CLASSIC_DEFAULT_MAXPTS, style={\"width\":\"140px\"})],\n",
    "                         style={\"marginRight\":16}),\n",
    "                html.Div([html.Label(\" \"), html.Button(\"Klassische RQA berechnen\", id=\"rqac_compute\", n_clicks=0, style={\"width\":\"240px\",\"height\":\"38px\"})]),\n",
    "            ], style={\"display\":\"flex\",\"flexWrap\":\"wrap\",\"alignItems\":\"flex-end\",\"gap\":8,\"marginBottom\":8}),\n",
    "            dcc.Graph(id=\"rqac_plot\", style={\"height\":\"560px\"}),\n",
    "            dash_table.DataTable(id=\"rqac_table\", page_size=5,\n",
    "                                 style_table={\"overflowX\":\"auto\"},\n",
    "                                 style_cell={\"padding\":\"6px\",\"fontFamily\":\"monospace\",\"fontSize\":12}),\n",
    "            html.Div(id=\"rqac_note\", style={\"opacity\":.7,\"marginTop\":6})\n",
    "        ]),\n",
    "    ]),\n",
    "])\n",
    "\n",
    "# ========================\n",
    "# FILTER-SYNC\n",
    "# ========================\n",
    "def _options_union_keep_selected(all_values, filtered_values, selected_values):\n",
    "    sel_set = set(map(str, selected_values or []))\n",
    "    vals = set(map(str, filtered_values or [])) | sel_set\n",
    "    if not vals:\n",
    "        vals = set(map(str, all_values or [])) | sel_set\n",
    "    return opt(sorted(vals))\n",
    "\n",
    "@app.callback(\n",
    "    Output(\"positions\",\"options\"), Output(\"play_types\",\"options\"),\n",
    "    Output(\"players\",\"options\"),  Output(\"games\",\"options\"),\n",
    "    Input(\"positions\",\"value\"),   Input(\"play_types\",\"value\"),\n",
    "    Input(\"players\",\"value\"),     Input(\"games\",\"value\"),\n",
    ")\n",
    "def sync_filters(pos_v, pt_v, pl_v, gm_v):\n",
    "    sel_for_pos = dict(positions=[], playtypes=pt_v or [], players=pl_v or [], games=gm_v or [], clusters=[], t_range=(0,3))\n",
    "    q_pos = filtered_df(sel_for_pos, [\"position_code\"])\n",
    "    pos_vals = q_pos[\"position_code\"].dropna().unique().tolist() if \"position_code\" in q_pos else positions_all\n",
    "    pos_opts = _options_union_keep_selected(positions_all, pos_vals, pos_v)\n",
    "\n",
    "    sel_for_pt  = dict(positions=pos_v or [], playtypes=[], players=pl_v or [], games=gm_v or [], clusters=[], t_range=(0,3))\n",
    "    q_pt = filtered_df(sel_for_pt, [\"play_type\"])\n",
    "    pt_vals = q_pt[\"play_type\"].dropna().unique().tolist() if \"play_type\" in q_pt else playtypes_all\n",
    "    pt_opts = _options_union_keep_selected(playtypes_all, pt_vals, pt_v)\n",
    "\n",
    "    sel_for_pl  = dict(positions=pos_v or [], playtypes=pt_v or [], players=[], games=gm_v or [], clusters=[], t_range=(0,3))\n",
    "    q_pl = filtered_df(sel_for_pl, [\"player_name\"])\n",
    "    pl_vals = q_pl[\"player_name\"].dropna().unique().tolist() if \"player_name\" in q_pl else players_all\n",
    "    pl_opts = _options_union_keep_selected(players_all, pl_vals, pl_v)\n",
    "\n",
    "    sel_for_gm  = dict(positions=pos_v or [], playtypes=pt_v or [], players=pl_v or [], games=[], clusters=[], t_range=(0,3))\n",
    "    q_gm = filtered_df(sel_for_gm, [\"game_id\"])\n",
    "    gm_vals = q_gm[\"game_id\"].dropna().unique().tolist() if \"game_id\" in q_gm else games_all\n",
    "    gm_opts = [{\"label\": GAME_LABELS.get(g, str(g)), \"value\": g} for g in sorted(gm_vals, key=lambda x: str(x))]\n",
    "\n",
    "    return pos_opts, pt_opts, pl_opts, gm_opts\n",
    "\n",
    "# ========================\n",
    "# OVERVIEW CALLBACK\n",
    "# ========================\n",
    "@app.callback(\n",
    "    Output(\"kpi-row\",\"children\"), Output(\"heatmap_xy\",\"figure\"),\n",
    "    Output(\"profile_means\",\"figure\"), Output(\"speed_hist\",\"figure\"),\n",
    "    Input(\"positions\",\"value\"), Input(\"play_types\",\"value\"),\n",
    "    Input(\"players\",\"value\"), Input(\"games\",\"value\"), Input(\"clusters\",\"value\"), Input(\"t_range\",\"value\"),\n",
    ")\n",
    "def update_overview(pos_v, pt_v, pl_v, gm_v, cl_v, tr_v):\n",
    "\n",
    "    cl_v_norm = [] if not cl_v else [c for c in cl_v if c != \"__ALL__\"]\n",
    "    sel = dict(positions=pos_v or [], playtypes=pt_v or [], players=pl_v or [], games=gm_v or [], clusters=cl_v_norm, t_range=tuple(tr_v or (0,3)))\n",
    "\n",
    "    q = filtered_df(sel, [\"play_uuid\",\"player_id\",\"game_id\",\"t_sec\",\"x_norm\",Y_COL,\"speed\",\"cl_kmeans\"])\n",
    "    def k(label, val):\n",
    "        return html.Div([html.Div(label, style={\"fontSize\":12,\"opacity\":.7}),\n",
    "                         html.Div(f\"{val}\", style={\"fontSize\":22,\"fontWeight\":600})],\n",
    "                        style={\"padding\":\"8px 12px\",\"border\":\"1px solid #eee\",\"borderRadius\":8,\"minWidth\":140})\n",
    "    kpis = [k(\"Zeilen\", f\"{len(q):,}\"),\n",
    "            k(\"Unique Plays\", q[\"play_uuid\"].nunique()),\n",
    "            k(\"Unique Spieler\", q[\"player_id\"].nunique()),\n",
    "            k(\"Unique Spiele\", q[\"game_id\"].nunique())]\n",
    "    \n",
    "    # Cluster-Meta\n",
    "    if CLUSTER_META:\n",
    "        kpis.append(k(\"K-Means k\", CLUSTER_META.get(\"k_best\", \"‚Äî\")))\n",
    "        kpis.append(k(\"Silhouette\", f\"{CLUSTER_META.get('silhouette', float('nan')):.3f}\"))\n",
    "\n",
    "    h = q\n",
    "    if len(h) > MAX_HEATMAP_POINTS: h = h.sample(MAX_HEATMAP_POINTS, random_state=42)\n",
    "    hm = px.density_heatmap(h, x=\"x_norm\", y=Y_COL, nbinsx=60, nbinsy=27, histnorm=\"\")\n",
    "    hm.update_layout(title=\"Dichte: x_norm vs. y (gesampelt)\")\n",
    "    hm.update_yaxes(scaleanchor=\"x\", scaleratio=53.33/120)\n",
    "\n",
    "    g = q.groupby(\"t_sec\").agg(mean_x=(\"x_norm\",\"mean\"), mean_y=(Y_COL,\"mean\"), mean_v=(\"speed\",\"mean\")).reset_index()\n",
    "    prof = go.Figure()\n",
    "    for col, name in [(\"mean_x\",\"mean x_norm\"),(\"mean_y\",\"mean y\"),(\"mean_v\",\"mean speed (yd/s)\")]:\n",
    "        prof.add_trace(go.Scatter(x=g[\"t_sec\"], y=g[col], mode=\"lines+markers\", name=name))\n",
    "    prof.update_layout(title=\"Mittelwerte je t_sec\", xaxis_title=\"t_sec\", yaxis_title=\"Wert\")\n",
    "\n",
    "    hist = px.histogram(q, x=\"speed\", nbins=SPEED_HIST_BINS, title=\"Geschwindigkeit (yd/s)\")\n",
    "    return kpis, hm, prof, hist\n",
    "\n",
    "# ========================\n",
    "# CRP CALLBACK (mit korrekter Off/Def-Trennung)\n",
    "# ========================\n",
    "def crp_off_vs_def(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Korrekte Trennung:\n",
    "      Offense = rows mit team_id == offense_team_id\n",
    "      Defense = rows mit team_id == defense_team_id\n",
    "    Aggregation: Mittelwerte je t_sec (x_norm, y, speed)\n",
    "    \"\"\"\n",
    "    needed = {\"t_sec\",\"x_norm\",Y_COL,\"speed\",\"team_id\",\"offense_team_id\",\"defense_team_id\"}\n",
    "    if not needed.issubset(df.columns):\n",
    "        # Fallback: keine Trennung m√∂glich\n",
    "        gg = df.groupby(\"t_sec\").agg(x=(\"x_norm\",\"mean\"), y=(Y_COL,\"mean\"), v=(\"speed\",\"mean\")).reset_index()\n",
    "        out = gg.rename(columns={\"x\":\"off_x\",\"y\":\"off_y\",\"v\":\"off_v\"})\n",
    "        out[\"def_x\"] = out[\"off_x\"]; out[\"def_y\"] = out[\"off_y\"]; out[\"def_v\"] = out[\"off_v\"]\n",
    "        out[\"dx\"] = 0.0; out[\"dy\"] = 0.0; out[\"dv\"] = 0.0\n",
    "        return out\n",
    "\n",
    "    is_off = df[\"team_id\"].astype(\"Int64\") == df[\"offense_team_id\"].astype(\"Int64\")\n",
    "    is_def = df[\"team_id\"].astype(\"Int64\") == df[\"defense_team_id\"].astype(\"Int64\")\n",
    "\n",
    "    off = df[is_off]\n",
    "    de  = df[is_def]\n",
    "\n",
    "    g_off = off.groupby(\"t_sec\").agg(x=(\"x_norm\",\"mean\"), y=(Y_COL,\"mean\"), v=(\"speed\",\"mean\")).add_prefix(\"off_\").reset_index()\n",
    "    g_def = de .groupby(\"t_sec\").agg(x=(\"x_norm\",\"mean\"), y=(Y_COL,\"mean\"), v=(\"speed\",\"mean\")).add_prefix(\"def_\").reset_index()\n",
    "\n",
    "    out = pd.merge(g_off, g_def, on=\"t_sec\", how=\"outer\").sort_values(\"t_sec\")\n",
    "    out[[\"off_x\",\"off_y\",\"off_v\",\"def_x\",\"def_y\",\"def_v\"]] = out[\n",
    "        [\"off_x\",\"off_y\",\"off_v\",\"def_x\",\"def_y\",\"def_v\"]\n",
    "    ].ffill().bfill()\n",
    "\n",
    "    out[\"dx\"] = out[\"off_x\"] - out[\"def_x\"]\n",
    "    out[\"dy\"] = out[\"off_y\"] - out[\"def_y\"]\n",
    "    out[\"dv\"] = out[\"off_v\"] - out[\"def_v\"]\n",
    "    return out\n",
    "\n",
    "@app.callback(\n",
    "    Output(\"crp_chart\",\"figure\"), Output(\"crp_table\",\"columns\"), Output(\"crp_table\",\"data\"),\n",
    "    Input(\"positions\",\"value\"), Input(\"play_types\",\"value\"),\n",
    "    Input(\"players\",\"value\"), Input(\"games\",\"value\"), Input(\"clusters\",\"value\"), Input(\"t_range\",\"value\"),\n",
    ")\n",
    "def update_crp(pos_v, pt_v, pl_v, gm_v, cl_v, tr_v):\n",
    "    cl_v_norm = [] if not cl_v else [c for c in cl_v if c != \"__ALL__\"]\n",
    "    sel = dict(positions=pos_v or [], playtypes=pt_v or [], players=pl_v or [], games=gm_v or [], clusters=cl_v_norm, t_range=tuple(tr_v or (0,3)))\n",
    "    q = filtered_df(sel, [\"t_sec\",\"x_norm\",Y_COL,\"speed\",\"team_id\",\"offense_team_id\",\"defense_team_id\"])\n",
    "    comp = crp_off_vs_def(q)\n",
    "\n",
    "    fig = go.Figure()\n",
    "    for col, name in [(\"off_x\",\"Offense mean x\"),(\"def_x\",\"Defense mean x\"),(\"dx\",\"Œîx (Off-Def)\")]:\n",
    "        fig.add_trace(go.Scatter(x=comp[\"t_sec\"], y=comp[col], mode=\"lines+markers\",\n",
    "                                 name=name, line=dict(dash=\"dash\") if col.startswith(\"d\") else None))\n",
    "    for col, name in [(\"off_v\",\"Offense mean v\"),(\"def_v\",\"Defense mean v\"),(\"dv\",\"Œîv (Off-Def)\")]:\n",
    "        fig.add_trace(go.Scatter(x=comp[\"t_sec\"], y=comp[col], mode=\"lines+markers\",\n",
    "                                 name=name, line=dict(dash=\"dash\") if col.startswith(\"d\") else None))\n",
    "    fig.update_layout(title=\"CRP: Offense vs Defense (x & v)\", xaxis_title=\"t_sec\")\n",
    "\n",
    "    cols = [{\"name\": c, \"id\": c} for c in comp.columns]\n",
    "    data = comp.round(3).to_dict(\"records\")\n",
    "    return fig, cols, data\n",
    "\n",
    "# ========================\n",
    "# RQA HELFER\n",
    "# ========================\n",
    "def pairwise_dist(A: np.ndarray, w: np.ndarray):\n",
    "    \"\"\"Gewichtete euklidische Distanzmatrix f√ºr NxD-Array A mit Gewichten w (D,).\"\"\"\n",
    "    A = np.asarray(A, float)\n",
    "    w = np.asarray(w, float).reshape(1, -1)\n",
    "    diff = A[:, None, :] - A[None, :, :]\n",
    "    return np.sqrt((diff**2 * w).sum(axis=2))\n",
    "\n",
    "def recurrence_matrix(arr: np.ndarray, target_rr: float, w=(1.0,1.0,1.0), standardize: bool = True):\n",
    "    A = np.asarray(arr, float)\n",
    "    if standardize:\n",
    "        mu = A.mean(axis=0, keepdims=True)\n",
    "        sd = A.std(axis=0, keepdims=True) + 1e-9\n",
    "        A = (A - mu) / sd\n",
    "    w = np.asarray(w, float)\n",
    "    D = pairwise_dist(A, w)\n",
    "    tri = D[np.triu_indices_from(D, k=1)]\n",
    "    if len(tri) == 0:\n",
    "        eps = 0.0\n",
    "        return (D <= eps).astype(int), float(eps)\n",
    "    eps = float(np.quantile(tri, target_rr))\n",
    "    return (D <= eps).astype(int), eps\n",
    "\n",
    "def rqa_metrics(R: np.ndarray, l_min=2, v_min=2):\n",
    "    N = R.size\n",
    "    RR = R.sum() / N if N > 0 else 0.0\n",
    "\n",
    "    # Diagonale Linien\n",
    "    diag_lengths = []\n",
    "    for k in range(-(R.shape[0]-1), R.shape[0]):\n",
    "        d = np.diag(R, k)\n",
    "        if d.size == 0: continue\n",
    "        run = 0\n",
    "        for val in d:\n",
    "            if val == 1: run += 1\n",
    "            else:\n",
    "                if run >= l_min: diag_lengths.append(run)\n",
    "                run = 0\n",
    "        if run >= l_min: diag_lengths.append(run)\n",
    "\n",
    "    DET  = (sum(diag_lengths) / R.sum()) if R.sum() > 0 and diag_lengths else 0.0\n",
    "    Lmax = max(diag_lengths) if diag_lengths else 0\n",
    "    L    = float(np.mean(diag_lengths)) if diag_lengths else 0.0\n",
    "    if diag_lengths:\n",
    "        _, cnts = np.unique(diag_lengths, return_counts=True)\n",
    "        p = cnts / cnts.sum()\n",
    "        ENTR = float(-(p * np.log(p + 1e-12)).sum())\n",
    "    else:\n",
    "        ENTR = 0.0\n",
    "\n",
    "    # Vertikale Linien\n",
    "    vert_lengths = []\n",
    "    for j in range(R.shape[1]):\n",
    "        col = R[:, j]\n",
    "        run = 0\n",
    "        for val in col:\n",
    "            if val == 1: run += 1\n",
    "            else:\n",
    "                if run >= v_min: vert_lengths.append(run)\n",
    "                run = 0\n",
    "        if run >= v_min: vert_lengths.append(run)\n",
    "\n",
    "    LAM = (sum(vert_lengths) / R.sum()) if R.sum() > 0 and vert_lengths else 0.0\n",
    "    TT  = float(np.mean(vert_lengths)) if vert_lengths else 0.0\n",
    "    if vert_lengths:\n",
    "        _, cnts_v = np.unique(vert_lengths, return_counts=True)\n",
    "        p_v = cnts_v / cnts_v.sum()\n",
    "        ENTR_V = float(-(p_v * np.log(p_v + 1e-12)).sum())\n",
    "    else:\n",
    "        ENTR_V = 0.0\n",
    "\n",
    "    return dict(RR=RR, DET=DET, L=L, Lmax=Lmax, ENTR=ENTR, LAM=LAM, TT=TT, ENTR_V=ENTR_V)\n",
    "\n",
    "def game_traj(df_game: pd.DataFrame, y_col: str):\n",
    "    # 4 Punkte je Spiel (0..3s) ‚Äì Mittelwerte √ºber Spieler\n",
    "    g = df_game.groupby(\"t_sec\")[[\"x_norm\", y_col, \"speed\"]].mean().reindex([0,1,2,3])\n",
    "    g = g.ffill().bfill()\n",
    "    return g.to_numpy(float)\n",
    "\n",
    "def build_full_series(df: pd.DataFrame, y_col: str, decim: int, maxpts: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Durchgehende 1 Hz-Serie aus der aktuellen Auswahl:\n",
    "    sortiert nach game_id ‚Üí play_uuid ‚Üí t_sec, pro Zeitstempel Mittelwert √ºber Spieler.\n",
    "    \"\"\"\n",
    "    if df.empty:\n",
    "        return np.empty((0, 3), float)\n",
    "\n",
    "    cols = [\"game_id\",\"play_uuid\",\"t_sec\",\"x_norm\",y_col,\"speed\"]\n",
    "    q = df[cols].copy().sort_values([\"game_id\",\"play_uuid\",\"t_sec\"])\n",
    "    q = q.groupby([\"game_id\",\"play_uuid\",\"t_sec\"], observed=True)[[\"x_norm\", y_col, \"speed\"]].mean().reset_index()\n",
    "\n",
    "    series = q[[\"x_norm\", y_col, \"speed\"]].to_numpy(float)\n",
    "    if decim is None or decim < 1: decim = 1\n",
    "    series = series[::decim]\n",
    "\n",
    "    if maxpts and series.shape[0] > maxpts:\n",
    "        series = series[:maxpts, :]\n",
    "\n",
    "    series = pd.DataFrame(series, columns=[\"x\",\"y\",\"v\"]).ffill().bfill().to_numpy(float)\n",
    "    return series\n",
    "\n",
    "# ========================\n",
    "# RQA CALLBACK (pro Spiel)\n",
    "# ========================\n",
    "@app.callback(\n",
    "    Output(\"rqa_plots_grid\",\"children\"),\n",
    "    Output(\"rqa_table\",\"columns\"),\n",
    "    Output(\"rqa_table\",\"data\"),\n",
    "    Output(\"rqa_note\",\"children\"),\n",
    "    Input(\"rqa_compute\",\"n_clicks\"),\n",
    "    State(\"positions\",\"value\"), State(\"play_types\",\"value\"),\n",
    "    State(\"players\",\"value\"),  State(\"games\",\"value\"),\n",
    "    State(\"t_range\",\"value\"),\n",
    "    State(\"rqa_target_rr\",\"value\"), State(\"rqa_lmin\",\"value\"), State(\"rqa_vmin\",\"value\"),\n",
    "    State(\"clusters\",\"value\"),             # ‚Üê NEU\n",
    "    prevent_initial_call=True\n",
    ")\n",
    "def compute_rqa(n_clicks, pos_v, pt_v, pl_v, gm_v, tr_v, target_rr, l_min, v_min, cl_v):  # ‚Üê NEU\n",
    "    cl_v_norm = [] if not cl_v else [c for c in cl_v if c != \"__ALL__\"]\n",
    "    sel = dict(\n",
    "        positions=pos_v or [], playtypes=pt_v or [], players=pl_v or [], games=gm_v or [],\n",
    "        clusters=cl_v_norm, t_range=tuple(tr_v or (0,3))\n",
    "    )\n",
    "    q = filtered_df(sel, [\"game_id\",\"t_sec\",\"x_norm\",Y_COL,\"speed\",\"home_abbr\",\"away_abbr\",\"cl_kmeans\"])\n",
    "\n",
    "    note = (\n",
    "        f\"Es werden max. {RQA_SHOW_MAX_GAMES} Spiele visualisiert. \"\n",
    "        f\"Cluster-Filter: {cl_v_norm if cl_v_norm else 'alle'}. \"\n",
    "        f\"Button gedr√ºckt: {n_clicks}. \"\n",
    "        \"Hinweis: Die pro-Spiel-Ansicht ist explorativ und nutzt 4 Zeitpunkte @ 1 Hz.\"\n",
    "    )\n",
    "    return plots, cols, rows, note\n",
    "\n",
    "\n",
    "# ========================\n",
    "# RQA CALLBACK (klassisch ‚Ä¢ komplette Serie)\n",
    "# ========================\n",
    "@app.callback(\n",
    "    Output(\"rqac_plot\",\"figure\"),\n",
    "    Output(\"rqac_table\",\"columns\"),\n",
    "    Output(\"rqac_table\",\"data\"),\n",
    "    Output(\"rqac_note\",\"children\"),\n",
    "    Input(\"rqac_compute\",\"n_clicks\"),\n",
    "    State(\"positions\",\"value\"), State(\"play_types\",\"value\"),\n",
    "    State(\"players\",\"value\"),  State(\"games\",\"value\"),\n",
    "    State(\"t_range\",\"value\"),\n",
    "    State(\"rqac_rr_mode\",\"value\"),\n",
    "    State(\"rqac_target_rr\",\"value\"), State(\"rqac_rr_preset\",\"value\"),\n",
    "    State(\"rqac_lmin\",\"value\"), State(\"rqac_vmin\",\"value\"),\n",
    "    State(\"rqac_decim\",\"value\"), State(\"rqac_maxpts\",\"value\"),\n",
    "    State(\"clusters\",\"value\"),                     \n",
    "    prevent_initial_call=True\n",
    ")\n",
    "def compute_rqa_classic(n_clicks, pos_v, pt_v, pl_v, gm_v, tr_v,\n",
    "                        rr_mode, target_rr, rr_preset, l_min, v_min, decim, maxpts, cl_v): \n",
    "    cl_v_norm = [] if not cl_v else [c for c in cl_v if c != \"__ALL__\"]\n",
    "    sel = dict(\n",
    "        positions=pos_v or [], playtypes=pt_v or [], players=pl_v or [], games=gm_v or [],\n",
    "        clusters=cl_v_norm, t_range=tuple(tr_v or (0,3))\n",
    "    )\n",
    "    q = filtered_df(sel, [\"game_id\",\"play_uuid\",\"t_sec\",\"x_norm\",Y_COL,\"speed\",\"cl_kmeans\"])\n",
    "    if q.empty:\n",
    "        empty_fig = go.Figure().update_layout(title=\"Keine Daten f√ºr die aktuelle Auswahl.\")\n",
    "        return empty_fig, [], [], \"\"\n",
    "\n",
    "    # Debug-Helfer zum Gegencheck in der Konsole\n",
    "    print(\"RQA classic ‚Äî Cluster-Filter:\", cl_v_norm if cl_v_norm else \"alle\",\n",
    "          \"| unique cl in q:\", sorted(map(int, q[\"cl_kmeans\"].dropna().unique())) if \"cl_kmeans\" in q else \"‚Äî\",\n",
    "          \"| N rows:\", len(q))\n",
    "\n",
    "    arr = build_full_series(q, Y_COL, decim=decim or RQA_CLASSIC_DEFAULT_DECIM,\n",
    "                            maxpts=maxpts or RQA_CLASSIC_DEFAULT_MAXPTS)\n",
    "\n",
    "    note = (\n",
    "        f\"Serie basiert auf Filterauswahl. Cluster-Filter: {cl_v_norm if cl_v_norm else 'alle'}. \"\n",
    "        f\"RR-Modus: {rr_mode}. Decimation: {int(decim or RQA_CLASSIC_DEFAULT_DECIM)}. \"\n",
    "        f\"Max. Punkte: {int(maxpts or RQA_CLASSIC_DEFAULT_MAXPTS)}.\"\n",
    "    )\n",
    "    return fig, cols, data, note\n",
    "\n",
    "\n",
    "# ========================\n",
    "# MAIN\n",
    "# ========================\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(debug=False, port=int(os.getenv(\"PORT\", 8050)), use_reloader=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
